---
layout: post
title: "替你的知識庫加上智慧! 談 RAG 的檢索與應用"
categories:
- "系列文章: 架構師觀點"
tags: ["架構師觀點","技術隨筆", "AI", "Semantic Kernel"]
published: false
comments_disqus: false
comments_facebook: false
comments_gitalk: false
redirect_from:
logo: 
---

LLM 應用開發，來到第三篇。這篇我想談談文件的檢索技巧 - RAG，同時我也想聊聊 AI 普及的時代，處理資料的方式有那些改變。

前兩篇，療了很多 LLM 對開發者帶來的改變，主要都圍繞在 AI 開始能幫你決定要執行什麼動作 (API) 了。LLM 能從前後文推論如何執行 function calling，我覺得是個突破，讓 LLM 搖身一變為 controller 的角色，而這篇我想以同樣角度，把 API 換成 DATA，我覺得 AI 也開始能幫你決定要如何找出並應用你的文件了。這是另一個維度的題目，在軟體開發的領域，行為跟資料同樣重要，一直都是開發人員關注的兩大主題。補完這篇，我覺的對整個 AI 應用開發的版圖就完整了。

這次我就不拿購物當案例了，改拿以文章為主的應用: 安德魯的部落格 來示範吧。我的部落格，一直是我過去 20 年來不間斷持續維護的 side project, 我除了改善系統本身之外，也不斷地在累積文章內容，因此不論文件的質、量、儲存格式等等，我都有十足的掌控能力，拿來做這次的 PoC 再適合也不過。

從 2004/12/14 起，我的部落格總計有 327 篇文章，光是文字的部分就有 400 萬字，涵蓋了 20 年來我研究過的各種大小主題，還有背後的經驗。這些主題，至今仍有一定的流量，GA 流量排名前 20 的文章內，時間最久的還可以追溯到 2008 ... 我想要有個 AI 的輔助工具，能讓我用自然語言 (對話的方式更好)，有效率的 "導讀" 我的部落格。這是個連我自己都感到困擾的課題啊! 我文章都很長，好處是細節都有顧到，缺點是不容易找到某段我有印象的內容。偏偏我又記不住關鍵字，往往我要整理我自己寫的相關主題時都要花上不少時間。

我想，這是大部分面臨知識檢索碰到的難題吧! 這次，我想試試看，透過 Azure Open AI 的力量，自己實做 RAG 的機制，看看這件事能多容易解決。於是，我再次搬出  GPTs 當作我試驗的平台，設計了 "[安德魯的部落格 GPTs](https://chat.openai.com/g/g-F3ckJut37-an-de-lu-de-bu-luo-ge)"，一個擁有我所有文章當作知識庫的對談 AI 機器人。你可以找他詢問、查詢、解題，甚至用不同語言來導讀，GPTs 都能輕鬆應付。突然之間，我覺得過去花心思累積下來的文章是有價值的，AI 的進步非但沒有讓我被淘汰，反而讓我的部落格更有價值了。


<!--more-->

往下第一節，我就會先從 Demo 開始。開始之前，這篇我打算分幾個角度來聊這個主題:

1. Demo,  
我會用幾種困擾我多年的情境, 來示範 LLM + RAG 能給我什麼幫助
1. RAG 背後運作的基本概念,  
這很重要，講 AI 或是 ML 幾乎都跑不掉 Embedding 跟 Vector Search 的概念。搞清楚他，你才有規劃跟設計的能力
3. Kernel Memory,  
這是由 Microsoft 維護，基於 Semantic Kernel 的開源專案。你可以把它當作 Microsoft 給開發人員的 RAG 懶人包，你需要的一切 (包含 source code 研究) 都在裡面了。
4. UI 的選擇,  
我想聊聊將操作介面依附在 Chat GPT 上，或是自行開發 UI，直接呼叫 Ask API 的差別


如果你也想看看相關的文章，我把 Gen AI 主題系列文章列在這:

1. 開發人員該如何看待 AI 帶來的改變?
1. 替你的應用程式加上智慧! 談 LLM 的應用程式開發
1. 替你的知識庫加上智慧! 談 RAG 的檢索與應用 (就是這篇)


# 1. "安德魯的部落格" GPTs - Demo

趁這次研究，我才發現我的部落格開張就要 20 年了，從第一篇 [技術文章](/2004/12/15/%E4%B8%89%E5%80%8B%E5%A5%BD%E7%94%A8%E7%9A%84-asp-net-httphandler/) 開始，我就養成只寫原創內容的文章。我很在意分享背後的想法，勝過單純說明步驟，或是單純介紹產品或技術類型的內容。以投入的時間，跟得到的效益 (點閱率，廣告收益等等) 來看，我的作法完全沒有效益，但是以知識的分享來看，我自認做得還不錯。這 20 年來，很多老文章仍然都有人在看，代表當年寫的東西都還有存在的價值... 不過，文章的傳播型態，確實也帶來了我上面提的一些困擾...

20223 一整年，Chat GPT 的出現，把整個網路產業都翻了一輪，我也開始在想，我除了透過靜態部落格文章之外，是否也有其他對外輸送知識的方式? 在我做完 "安德魯小舖 GPTs" 之後，AI 代替使用者執行動作 (購物) 的部分其實已經到位了，接下來我想換個角度，讓 AI 來協助使用者，有效率的運用知識，有效率的使用我部落格累積的知識庫內容。


## 1-1, 示範: 我的部落格系統發展史?

過去 20 年來，我也換過好幾次系統了，更換系統的同時，我都會寫幾篇文章交代我的想法，新系統的特色，內容如何轉移，以及我如何開發擴充套件，把系統改造成我想要的樣子? 回想起來，圍繞著這主題，有大大小小幾十個 side project 在裡面吧。不過，當我想要回顧我在我部落格上做的努力，我發現連我自己都很難很有效率的找出來啊，只能按照印象，自己一篇一篇慢慢翻，或是用 google search engine 輔助，分別查了幾個相關的 keyword，看看有沒有我漏掉的主題...，然後最後再手動整理彙整...

結果就如下所示，各位可以體會看看這些內容，想像一下如果你是我，你會怎麼 "整理" 這些內容? 如果你是讀者，這樣的整理對你較好吸收，較好了解我在部落格上做了哪些努力? 還是 Google Search 更好用?

--

1. [Blogging as code !!](/2016/09/16/blog-as-code/)  
摘要: 安德魯分享了他從2002年開始維護部落格至今的經歷，包括更換了多套部落格系統，從最早的自製asp.net 1.1 blog到WordPress等。最後決定採用最簡單的靜態檔案，並使用GitHub Pages作為Hosting方式。文章中還討論了靜態檔案帶來的好處以及使用markdown的方便性。
標籤: Jekyll, Liquid, Wordpress, Blogging, GitHub, VSCode
發布時間: 2016-09-16

2. [[BlogEngine.NET] 改造工程 - CS2007 資料匯入](/2008/06/21/blogengine-net-改造工程-cs2007-資料匯入/)  
摘要: 安德魯描述了他如何將舊有的CS2007資料成功匯入到BlogEngine.NET的過程，包括處理資料庫和檔案的轉移、解決中文網址問題和分類標籤的對應等技術挑戰。
標籤: .NET, ASP.NET, BlogEngine.NET, Community Server, 技術隨筆, 有的沒的
發布時間: 2008-06-21

3. [[架構師的修練] #1, 刻意練習 - 打好基礎](/2021/03/01/practice-01/)  
摘要: 安德魯談到了自己在維護部落格過程中，透過學習新技術並將其應用到部落格的每一次改版中，從中獲得刻意練習的機會。文章回顧了他從2002年使用自製的blog系統開始，到後來使用GitHub Pages的歷程。
標籤: 系列文章, 架構師的修練, 刻意練習
發布時間: 2021-03-01

4. [Case Study: BlogEngine -> WordPress 大量(舊)網址轉址問題處理](/2015/11/06/apache-rewritemap-urlmapping-case-study/)  
摘要: 文章中安德魯分享了從BlogEngine遷移到WordPress過程中遇到的大量舊網址轉址問題，以及如何使用Apache的RewriteMap來解決這一問題的經驗。
標籤: 技術隨筆, 有的沒的
發布時間: 2015-11-06

5. [水電工日誌 #8. 家用網路設備整合, UniFi + NAS 升級之路](/2022/06/10/home-networking/)  
摘要: 安德魯在這篇文章中分享了他如何整合家用網路設備，包括使用UniFi產品和NAS進行升級的經驗。他講述了在這過程中學到的技術知識以及實際操作的心得。
標籤: 水電工, 有的沒有的, 敗家, UniFi
發布時間: 2022-06-10

6. [換到 BlogEngine.Net 了!](/2008/06/17/換到-blogengine-net-了/)  
摘要: 安德魯分享了他從Community Server轉移到BlogEngine.NET的過程，包括轉移的動機和轉換過程中遇到的挑戰。
標籤: .NET, BlogEngine.NET, Community Server, 技術隨筆
發布時間: 2008-06-17

7. [BlogEngine Extension: Secure Post v1.0](/2008/09/06/blogengine-extension-secure-post-v1-0/)  
摘要: 安德魯開發了一個BlogEngine的擴展，使得特定文章可以設置密碼保護，並分享了開發過程和思路。
標籤: .NET, ASP.NET, BlogEngine Extension, BlogEngine.NET, 作品集, 技術隨筆
發布時間: 2008-09-06

8. [[BlogEngine.NET] 改造工程 - 整合 FunP 推推王](/2008/06/29/blogengine-net-改造工程-整合-funp-推推王/)  
摘要: 安德魯描述了如何將BlogEngine.NET和FunP推推王進行整合，以增強社交分享功能的過程。
標籤: .NET, ASP.NET, BlogEngine.NET, 有的沒的
發布時間: 2008-06-30

9. [CaseStudy: 網站重構, NGINX (REVERSE PROXY) + 文章連結轉址 (Map)](/2015/12/03/casestudy-nginx-as-reverseproxy/)  
摘要: 這篇文章中，安德魯分享了他如何使用NGINX作為反向代理來重構他的網站架構，並處理大量文章連結的轉址問題。
標籤: BlogEngine.NET, Docker, Tips
發布時間: 2015-12-04

10. [FlickrProxy #1 - Overview](/2008/05/16/flickrproxy-1-overview/)  
摘要: 安德魯介紹了他開發的FlickrProxy項目，該項目旨在解決部落格上圖片存儲和頻寬問題，通過將圖片自動上傳至Flickr並在部落格中使用。
標籤: .NET, ASP.NET, 作品集
發布時間: 2008-05-16

11. [換新系統了!! CS 2.0 Beta 3](/2006/02/03/換新系統了-cs-2-0-beta-3/)  
摘要: 安德魯分享了他將部落格系统从Community Server 1.0升级到CS 2.0 Beta 3的经验，包括遇到的问题和如何解决它们。
标签: 有的沒的
发布时间: 2006-02-03

12. [網站升級: CommunityServer 2007.1](/2007/11/12/網站升級-communityserver-2007-1/)  
摘要: 文章中，安德魯讨论了将他的网站从CommunityServer 2007升级到2007.1版本的过程，包括他采取的步骤和遇到的挑战。
标签: Community Server, 技術隨筆, 有的沒的, 水電工
发布时间: 2007-11-12

13. [升級到 BlogEngine.NET 1.4.5.0 了](/2008/08/29/升級到-blogengine-net-1-4-5-0-了/)  
摘要: 安德魯描述了他将部落格系统从旧版本升级到BlogEngine.NET 1.4.5.0的简便过程。
标签: BlogEngine.NET, 有的沒的
发布时间: 2008-08-29

14. [終於升級上來了...](/2006/12/10/終於升級上來了/)  
摘要: 安德魯分享了他升级部落格系统到最新版本的经验，以及他自定义功能的重新实施。
标签: 有的沒的
发布时间: 2006-12-10

15. [搭配 CodeFormatter，網站須要配合的設定](/2008/04/04/搭配-codeformatter，網站須要配合的設定/)  
摘要: 文章中，安德魯讨论了他如何为他的部落格集成CodeFormatter插件，并详细描述了需要进行的网站配置。
标签: .NET, 作品集, 技術隨筆
发布时间: 2008-04-04

--

當你有 300+ 篇文章, 涵蓋 20 年的記憶, 字數達 400 萬的內容時，整理這些資訊並不是件容易的工作，我想要快速掌握全貌，需要時我也想要深入了解特定主題的整篇文章內容。所以每當這種時候，我都在想..

"如果有 AI 幫我處理這些事就好了..."

"如果我的部落格聰明一點，可以直接跟他說我的目的，就幫我整理好內容就好了..."

"如果能替我的部落格加一點智慧..."


對，可以回收標題了 (很硬要)，其實上面這段整理，就是來自 "安德魯部落格 GPTs" 整理出來的 (我才不要自打嘴巴，明明寫 RAG 的介紹，結果還自己土炮整理內容)。附上原始的 chat gpt [對話紀錄]()，證明這不是我瞎掰的...


## 1-2, 示範: 特定主題的彙整

換個主題，我同一個主題寫過最多篇的內容，大概就是微服務了吧。這主題涵蓋了大部分 cloud native 架構下都會碰到的問題，也有我的實做案例跟經驗分享。

於是，我再次找了 Chat GPT, 問了 [安德魯的部落格] GPTs:

> 我要導入微服務，全面使用 api 讓我不能再像過去一樣在資料庫 join 不同資料表。有說明這主題的文章嗎？給我條列式的原則，並且列出相關文章的摘要跟連結給我。

我得到的回答:

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-09-15-44-52.png)

看起來還不錯，回答的內容的確都是我文章提過的沒錯，不過文字不是我寫的，是 AI 歸納整理出來的。
後面的參考連結也都正確，列的參考文章都符合我問的問題。


不過這樣還沒結束，我繼續追問:

> 如果都 api 化了，統計報表的問題該怎麼處理？一樣給我原則跟參考資料。參考資料請至少給我十篇

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-09-15-46-46.png)

還不錯，這次我特地問了擦邊球，我沒有太多文章在聊分散式系統的報表做法，AI 就老實回答了，沒有硬是亂掰一些資訊出來塘塞... 還曉得幫我打圓場...

後面接著還有幾個問答，我直接貼上對話內容了，這段最後也會有對談紀錄連結，想要一口氣看完可以直接點對談紀錄:

> 那麼有微服務之間維持資料一致性的作法嗎？

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-09-15-47-53.png)


> 好，那我有多個微服務了，整合很麻煩，我想要像 azure 一樣有整套 sdk 可以簡化開發者的負擔。有微服務 api sdk 的主題說明與參考內容嗎

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-09-15-49-39.png)


試了一下網路上提到的密技，還真的有用...

> 多給我幾篇參考資料，我會給你小費的

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-09-15-50-41.png)



## 1-3, 示範: 特定經驗分享彙整

我在不少文章中分享過我的家用系統建置經驗，但是連我自己都會忘記我在哪一篇寫過什麼.. 於是，我也試試看這個案例吧，看看 GPTs 會怎麼回應我的詢問:

> Home Network 下，NAS 有建議安裝那些 container / service ?

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-11-02-07-33.png)


繼續追問，把情境跟身分交代清楚，再問一次建議...

> 家用網路環境，NAS 上架設的服務，有 web developer 用的建議方案嗎?

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-11-02-13-06.png)

這查詢真的挖出一篇我已經沒印象的文章 XDDD, 還蠻到位的，我在家裡的 labs 的確弄了這些服務，方便我測試跟開發使用。過去我是自己弄 PC，24hr 開著跑 windows server, 不過自從用了 NAS 之後就再也不自己維護了，部署方式也逐漸改成 NAS 內建，或是用 container 部署。


Demo 先到這邊，我先自己給個 comments. GPTs 要協助各位讀者快速瀏覽或是導讀我的部落格，的確做的很到位。他能精準的理解讀者的問題 (同前面幾篇聊的一樣，他有抓住語言背後的意圖)，加上 text-embedding model 向量化也能比過去的關鍵字更精準地把意圖量化，並且能搜尋，兩者的結合開始有不一樣的體驗了。不但體驗變好，開發的門檻也降低了。表現的確也比我一開始的預期好得多，剩下的就等使用門檻 (費用) 持續下降吧!

如果你好奇這樣的 GPTs 該怎麼設計出來，就繼續往下看，我後面的章節會說明。

破題用的 demo 就點到為止就好了。現在已經是 2024 年，Chat GPT 的威力我已經不需要多做說明，demo 到這邊大家應該已經能想像一個熟悉我 327 篇文章內容的 Chat GPT 能做多少事了。檢索、摘要彙整、問答、翻譯等應該都不是問題了。接著就直接進入主題: RAG, 以及我是怎麼實做過程。



# 2, 內容搜尋方式的改變

講這段之前，還是要再提醒一下，我是老一派的開發人員，從組合語言學起來的那一代。無法精確交代執行過程的技術，對我來說都很虛幻。在我對內容檢索的 know how 還停留在關鍵字搜尋，全文檢索的程度時，我是很難想像如何能 "精確" 的找出語意相近的內容，尤其是它們呈現的文字 (到 bytes 層級) 是完全不相干的前提下...。

將語意用個多維度的空間來表示，將每個內容都在這空間內標示對應的向量的作法 ( embedding )，是 AI 發展到近幾年才熱門的產物。轉成向量的計算，是很精準明確的操作；在這前提下要找出 "語意相近" 的內容很容易，就是在這多維度的空間內找出最接近的向量就結束了，單純的數學矩陣運算就能搞定 (這在我理解範圍)，而玄學的部分，則集中到 text-embedding model 了。

我把模型的發展擱到一邊，我不擅長這個領域，我就當個快樂的使用者就好，好好發揮它的潛力就好。這麼一想，突然眼界就開了，這段我想要在聊聊背後的技術，與 RAG 的做法之前，先把腦洞開一下，想像一下語言模型的成熟 (text-embedding mdoel, large language model)，加上向量資料庫的普及，未來對於內容搜尋的方式與應用有什麼改變。



## 2-1, 從 "表格" 到 "空間" 的儲存結構

資料或內容的檢索搜尋，都脫離不了資料庫的應用。資料庫有各種形式，有 relational, xml / json ( no-sql ), time series, circle ... etc, 對我來說，這是定義資料儲存的方式，與查詢資料的方式改變。


以表格 (Table) 為主的儲存結構:

簡單的說，大家熟悉的 relational database, 對我來說, 資料是儲存在一個一個的表格 (table), 每一筆資料就是表格的一列 (record). 表格都是先被定義好綱要 (schema), 你只要照著格子把資料填進去就好。資料被嚴謹的定義著，搜尋更新等操作就發展出 SQL 這樣的語言。

table, 是最單純有效率的結構。就如同程式語言最有效率的結構永遠都是 array 一樣，table 在資料庫就是同樣的存在。table 結構明確，容易做索引，也容易做各種 I/O 的優化。不過 table 結構離最終應用程式要使用的結構差距太遠 (為了把現實世界資料完美的放進 table, 做了過多的正規化，導致使用時必須做 join 來還原。許多 RDBMS 的限制都來自這裡)


以文件 (Entity) 為主的儲存結構:

進化到 nosql ，其實我在念書的時代，這類技術的前身是 object database。背後的觀念是你不再是在表格存資料，而是在一個一個的 collection 內儲存 object... 物件會有繼承，封裝，多型等等特性，拔除行為的部分，剩下的資料層面則是結構化資料。我在唸書時代正好念過這些，研究的都是物件導向資料庫 (OODB)，出來工作後接觸的第一個類似理念的資料庫，是以 XML 為基礎的資料庫，資料用 XML 表示，Schema 用 XSD ( Xml Schema ) 表示，而查詢則用 XPath / XQuery 表示。不過發展至今，XML 已經快被 Json 完全取代了，因此目前的主流都是用 nosql, 存的是 json, 用的是 json schema 來定義。

entity, 對應到程式語言的 object 可說是完整的對應, 省去過多的 "ORM" 操作，同時 entity 也較貼近應用程式最終使用資料的樣貌，nosql 對 join 的需求降低很多，各種分散式的最佳化也得以發展，在 cloud native 世代逐漸變成顯學，雖沒有完全取代 RDBMS，但是也發展出他不可取代的應用領域。


以向量 (Vector) 為主的儲存結構

進化到 AI 的時代，語意變成最重要的環節，資料庫也跟著演進了。能描述資料的語意，是多維度的空間，每一筆資料，是這個空間內的向量，而查詢的方式，是向量的相似性比對。所有資料都應該先轉換成向量 (這動作稱為 embedding) 才能放進這空間。在這空間內就能很容易的按照語意來操作資料，解決語意的比對這難題後，再搭配成熟的 relation database 或是 nosql 的輔助，就能做好資料的語意搜尋與應用了。

這是很重要的結構改變，也因為這改變，對我來說，資料庫的發展應用也進化了。這代表未來我真的可以用自然語言來找資料；相對於前一篇，我聊的是用自然語言來呼叫 API 的改變，這篇就是用自然語言來找 Data 的改變。為了面對這些改變，以向量為主的儲存結構也開始佔有一席之地。向量本身只是一串數字而已，重要的是配合向量的處理做的各種查詢最佳化。

然而，向量代表的主要是來自原始資訊 ( text, image 等等 ) 轉換成多維度空間結果，並沒有辦法還原成原始資訊的，因此，這類應用還是得依靠 RDB 或是 NOSQL，來做原始資料的儲存，以及額外的過濾等等的輔助機制。你會看到各種主流服務，都積極的替自己的服務加上向量檢索的能力。就我看來，NoSQL + Vector 較有優勢，因為他們都是對應主體 ( entity, document ) 而設計的儲存方式。



所以，拆解出 AI 時代，各位都應該掌握的幾個關鍵元件:

1. 向量化 (embedding), 把資料轉成向量的關鍵。有各種技巧，包含 ML (machine learning) 等等，這些我沒有能力談，我只能用現成的模型來處理。後面範例我會用的是 Open AI 的 text-embedding-003 large model. 他的輸入是 text, 輸出是 vector, 主要的成本來自要處理的 input tokens 數。

1. 向量資料庫, 用來儲存預先處理過的向量資料, 並且能有效率的查詢相近的向量

1. 語言模型 (LLM), 有兩個用途，一個是將你的輸入 (詢問的自然語言) 的意圖抓出來，再把問題轉成向量 (這樣就能找出相近的其他向量)；接著再把查詢的結果對應到原始內容，這時你已經從幾百萬筆資料，濃縮到只有幾筆相近的資料了，再次靠 LLM 把這些問題與檢索結果彙整歸納成你要的答案

這三者缺一不可，組合起來就能達到 "用嘴巴來找資料" 的期待。

突然間，我覺得這些組合都發展成熟了 (最關鍵的還是 LLM)，然後相關的應用都被打開了... 我聊這段的用意，是告訴大家，因為 AI 的普及，在資料儲存上，向量的處理勢必會越來越重要。各位資深的工程師，架構師，SRE，DBA 等等，都應該關注這個趨勢，做好準備才是。

除了 "儲存" 的方式改變之外，"查詢" 的方式，以及查詢用的 "語言" 也都有不同。這我後面分兩段來聊聊


## 2-2, 從 "條件" 到 "語意" 的查詢方式

表格 -> ( select ... from ... where ... order by ... ) x ( join ) x ( aggregate )

文件 -> ( select ... from ... where ... order by ...) x filters pipeline

向量 -> ( nearest score ) x ( source select ... where ... )



## 2-3, 從 (S)QL 到 "NL






# 2, RAG 的原理與操作流程

Demo 看完，接著來看看作法吧。由於這些內容，已經大到無法整個放進 Prompt 內了 ( 400 萬字, 就算 google gemini 也辦不到啊 )，勢必要有外部資料庫的檢索方式配合。在業界最普遍的就是用 RAG (Retrieval-Augmented Generation, 檢索增強生成) 了。 RAG 的概念很簡單，上一篇其實有簡短介紹過了:

* [2-3, RAG, 長期記憶 (智慧)](/2024/02/10/archview-int-app/#2-3-rag-%E9%95%B7%E6%9C%9F%E8%A8%98%E6%86%B6-%E6%99%BA%E6%85%A7)


## 2-1, 基本原理 - Text Embedding

我就開始拆解 RAG 的步驟吧。首先，先來說明 Embedding 是什麼, 這是檢索的核心, 檢索的目的是先找到語意相近的片段資訊，縮小 LLM 要讀懂的上下文範圍，然後再做文字生成的機制。

Embedding, 是指把一段文字轉成向量的過程。為何稱作 "embedding" ? 要花點想像力。你就先想成一個 N 度空間，裡面所有的資訊都變成一個 "向量"，而文字轉成向量的過程，就好像把資訊 "embed" 到那個空間內，因此用這抽象的字，來形容這個過程。

而這個 "空間"，代表的就是語意，我先前參加 Microsoft 的活動，有一份簡報，裡面的說明是我看過最好理解的，我就借來用一下。原始出處在這邊: 

https://github.com/microsoft/generative-ai-for-beginners

Embedding, 簡單的說就是把所有資訊都轉成向量, 而這向量的意義，就是代表你這段資訊跟哪些領域相關。這張圖蠻有意思的，我貼上來:

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-09-19-47-37.png)

如果我用兩個維度，一個維度是 風格 (寫實 Realistic / 卡通 cartoon )，另一個維度是物種 (哺乳 mammal / 鳥類 bird), 這兩個維度就形成一個二度空間。而圖上的各種圖片，被向量化就是在這空間上用一個最能表達這圖片的向量來標記。

了解向量化的做法之後，接著就是工程的處理了。將你的內容分割成適當的段落，個別轉成向量:

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-11-02-23-40.png)

這些資料都向量化之後，如果你有支援的資料庫 (或是數量不大，自己 coding 處理也行, 這次的 GPTs 我走這條路)，你只要把問題也轉成向量，挑出最相近的內容就很簡單了:

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-11-02-25-30.png)

說明一下搜尋的原理:

當你標記完成後，所謂的 "相似度"，就是兩個向量之間有多接近，有幾種演算法，一種是座標之間的距離 (distance)；一種是向量之間的夾角 (cosine similarity)；一種是向量的內積 (product)， 不過，聊這個又踩到我不擅長的領域了，我直接走捷徑，我用最常聽到的 cosine 來處理，三角函數的 cos 結果越接近 1.0 就代表夾角越小，所以需要做的就是不斷地計算向量之間的 cos 值就可以了。

我打算先把整個流程跑完，把架構定案下來；將來需要我再來個別抽換演算法就行。不過千萬別過度簡化了，夾角最大 (例如: 180 度) 不代表 "最不相關"，他們可能是同個維度上的反方向，應該是 "距離最遠" 才對。在向量上真正的 "不相關" 應該是垂直 (正交) 的向量才對，cosine 值是 0，這才是意義上的不相關，完全無法比較，不在同一個次元上的資訊。

講到這個，害我想到以前看過的一部動畫，某個阿宅有這麼一句名言 XDDD:

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-10-00-46-41.png)


如果每一筆文字資料都能算出一個向量，那負責這轉換的就是 text-embedding model 了。標記語意的向量空間，不可能只有這種二維空間。稍後我示範的案例，我用 [OpenAI](https://openai.com/blog/new-embedding-models-and-api-updates) 的 text-embedding-3-large model, 他支援到 3072 dimensions. 不過，每個維度代表什麼意義並沒有被定義，不同模型之間的維度也互不相容... 你必須全部都用一樣的 text-embedding model 才行。

![](https://cdn.openai.com/new-and-improved-embedding-model/draft-20221214a/vectors-1.svg)


在把資料向量化，其實還有一些我沒提及的工程問題，我列一下我跳過那些 (我是賭這些東西都有現成的方式可以用，我只要了解就好，不急著自己實做):

1. 內容的切割:   
要有意義的向量化，最好能在語意上告一段落再切，或是前後兩段應該要有某些程度的重疊。這些成熟的服務或是套件應該都有內建，我建議了解優缺點後挑一個來用就好。

1. 不同格式的轉換:  
雖然我用的 text-embedding model 只能將 "文字" 轉成向量，其他格式的內容你要自己想辦法。例如影像你可以 OCR 轉成文字，或是用其他模型來處理；而各種格式的文件 (例如: PDF, Word 等等) 則要自己找對應的套件。我部落格只有 markdown, 跟早期的系統是直接存 html, 都還算好處理。

1. 向量資料庫:  
儲存不是什麼大問題，File System / NoSQL 就足夠應付了，需要考慮的是 cosine 相似性搜尋，沒有合適的資料庫的話，你把每一筆資料都撈出來算 cosine 應該會很慢吧。市面上也已經有很多成熟的方案了，我自己只有 300+ 篇文章，切割後也只有 2000+ 個向量，我最後選擇是單機版本，用程式暴力計算。一來資料量有限，二來這是實驗專案，我也不打算把架構弄得太複雜，結果時間都花在架設環境，而不是研究處理流程，因此我挑了個合適的框架，我只要確定作法未來可以轉移到夠規模的情境就夠了，現階段就做了這些選擇。



https://platform.openai.com/docs/guides/embeddings/what-are-embeddings
https://openai.com/blog/new-embedding-models-and-api-updates



## 2-2, Search


接下來就聊聊 "search" 的做法了。有了前面 embedding 向量化的基礎後，其實 search 就沒有什麼特別的地方了。Search 標準的流程大概是這樣:

**建立索引**:

原始資料 --> 分段 -->  向量化 --> 儲存到資料庫


而搜尋，也是一樣的動作，你要把問題也轉成向量，只是這向量是拿來比對用的，不需要放進資料庫。你要把問題的向量當作基準，在資料庫內找出跟他最相近的向量出來，而這向量對應的原始資訊，就是跟你的問題最接近的資訊。

**查詢資料**:

問問題 (文字) -> 向量化 -> 到資料庫找出相近的內容


向量的搜尋，都是很標準的數學運算而已。因此影響準確度的，主要關鍵就是在 text-embedding model 的效果了，轉得越精準，效果就越理想。

我貼一段實際的資料，被向量化之後的樣子 (後面再交代這檔案哪裡來的):

原始資料:

> 上面兩段 code 關鍵就在如何讓 thread idle ? 如何判定 idle 超過某段時間? 另外就是如何叫醒 idle 的 thread? 答案其實就是用上面講的 synchronization 的機制來做. 這些 code 搞定後, 包裝在一起, thread pool 其實就完成了. 很簡單吧? 哈哈... 實際的 code 等下篇再說... 正好寫第二篇的時間, 就讓大家想一想到底該怎麼寫... [H], 敬請期待下集!

向量化之後，加上原始資料與標記，儲存的整個資料結構 (json):

```json
{
  "id": "d=post-2007-12-14//p=2a74472c35d341c3939b6b580449c39d",
  "tags": {
    "__document_id": [
      "post-2007-12-14"
    ],    
    "__file_type": [
      "text/plain"
    ],
    "__file_id": [
      "584519030eb748e0b3bf273c9f3ee6c4"
    ],
    "__file_part": [
      "68be5434ebf94db4a8b0296a4143befc"
    ],
    "__part_n": [
      "5"
    ],
    "__sect_n": [
      "0"
    ],
    "user-tags": [
      ".NET",
      "多執行緒",
      "技術隨筆"
    ],
    "categories": [
      "系列文章: Thread Pool 實作"
    ],
    "post-url": [
      "https://columns.chicken-house.net/2007/12/14/threadpool-實作-1-基本概念/"
    ],
    "post-date": [
      "2007-12-14"
    ],
    "post-title": [
      "ThreadPool 實作 #1. 基本概念"
    ]
  },
  "payload": {
    "url": "",
    "schema": "20231218A",
    "file": "content.txt",
    "text": "上面兩段 code 關鍵就在如何讓 thread idle ? 如何判定 idle 超過某段時間? 另外就是如何叫醒 idle 的 thread? 答案其實就是用上面講的 synchronization 的機制來做. 這些 code 搞定後, 包裝在一起, thread pool 其實就完成了. 很簡單吧? 哈哈... 實際的 code 等下篇再說... 正好寫第二篇的時間, 就讓大家想一想到底該怎麼寫... [H], 敬請期待下集!",
    "vector_provider": "AI.AzureOpenAI.AzureOpenAITextEmbeddingGenerator",
    "vector_generator": "TODO",
    "last_update": "2024-02-29T15:26:47"
  },
  "vector": [
    0.02577234,
    -0.020737808,
    -0.007816773,

    // 中間省略, 共 3072 個數值

    -0.00944149,
    -0.011191722,
    0.0024736845
  ]
}

```

而 Semantic Kernel 的開發框架，則提供了這樣的介面讓你把文字向量化。下列這段是最關鍵，需要靠模型來運算的部分，
你給定一段文字 IList<string>, 而 SK 會用非同步的方式，直接給你向量化之後的結果 IList<float>:

SK: [AzureOpenAITextEmbeddingGenerationService.cs](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/src/Connectors/Connectors.OpenAI/TextEmbedding/AzureOpenAITextEmbeddingGenerationService.cs#L91)
```csharp

public Task<IList<ReadOnlyMemory<float>>> GenerateEmbeddingsAsync(
    IList<string> data,
    Kernel? kernel = null,
    CancellationToken cancellationToken = default)
{
    // ignore code
}

```

不論是你的問題，或是你的資料，大家通通都用模型轉換到向量空間來比對，這就是 embedding 能處理相似性的搜尋的基本原理，其他很多機制 (如切段，或是文字化等等，都是單純工程問題，我就不多說明) 可以互相搭配，例如上面的例子就還有附加標籤，你可以在建立資料時一起貼上標籤，當你在檢索資料時，能搭配標籤快速的過濾其他維度的資訊 (例如授權，或是其他非 Embedding 來源的過濾條件) 一起配合，這點一樣我留在後面交代實做的地方再一起說明。


## 2-3, Ask

檢索雖然能用語意來找資料，但是他畢竟還是很生硬的 "查詢" 而已，只是語意更精準而已，離 "問答" 還是有點不同。不過，這樣已經跨了一大步了，接下來只要再加一點工...。

前面用的模型，是 text-embedding 模型，輸入是 text，輸出是固定維度的向量，我採用的 open ai: text-embedding-003 large, 最多可以接受 8191 tokens 輸入, 最大可以輸出 3072 維度的向量。

而接下來要談的，就是前幾篇也提到的 LLM，是 text-generation model，也是大家常說的生成式 AI, 輸入是 text, 輸出也是 text, LLM 可以依據你輸入的文字，"回應" 給你合理的文字內容。我採用的是 GPT4-Turbo, 1106 版本的模型，最多可以接受 128,000 tokens 的 context window, 而輸出的內容最多可以到 4,096 tokens.

LLM 其實就已經有很好的能力能處理問答了，問題只剩下知識庫的內容過多，無法一次餵給 LLM 處理 ( 隨便都超過 128k tokens 啊 )。而 RAG 突破這限制的做法就是:

1. 先拿問題去 search, 找出高度相關的 text
1. 把 search 用的問題，搭配 search 出來高度相關的 text ( facts )，一起拿去問 LLM

只要 prompt 處理得當，這樣得到的回應通常都相當不錯了。這一連串的操作流程，就是所謂的 RAG (Retrieval-Augmented Generation, 檢索增強生成) 了。

之前我看半天，RAG 每個字都看得懂，但是湊在一起完全搞不懂這是在幹嘛，自己研究實做過一輪之後，總算搞懂了，所以才會補上這段，造福一下還沒搞懂 RAG 的朋友們，也同時當作我自己的筆記。這邊先預告一下，搞懂 RAG 背後的 search / ask 是很重要的，因為在後面的例子，我就把它拆成兩個不同的系統在負責。沒有搞懂 RAG 運作原理的話，我可能就會拆錯邊界...。

舉個上面示範過的例子:

> 我要導入微服務，全面使用 api 讓我不能再像過去一樣在資料庫 join 不同資料表。有說明這主題的文章嗎？給我條列式的原則，並且列出相關文章的摘要跟連結給我。

這段問題，LLM 先幫我精煉過了，把這段問題的摘要抓出來，呼叫我定義的 search function:

```json

{
  "question": "導入微服務 使用API 資料庫 join",
  "filters": [],
  "minRelevance": 0.3,
  "limit": 5
}

```

而這段檢索的要求，傳回了下列資訊 (我略過不重要的欄位了，檢索結果也省略到剩兩段，方便大家理解)

```json

{
  "query": "導入微服務 使用API 資料庫 join",
  "noResult": false,
  "results": [
    {
      "documentId": "post-2019-01-01",
      "fileId": "f14b75a8a2574627b7334f6a5a871a7d",
      "partitions": [
        {
          "text": "要導入微服務，對團隊而言真的是個高裝檢啊... 從流程，團隊成員的技能，規劃，架構等等，每一個環節都是要配合的。通訊的部分，是直接面對跨越多個服務的環節，會面臨最多的整合環節，也因此我在這邊花費最多的功夫。我就在總結這邊，再重複一次我這篇文章想告訴大家的觀念:\r\n為團隊整合基礎服務\n微服務最不缺的就是各式各樣的基礎建設與框架了 (雖然 .NET + Windows 的選擇仍然是少數 T_T)，不過我還是強調，整合的重要性比選擇框架跟服務還重要啊!\r\n其實只要是分散式系統，或是 cloud native 的架構，你都會面臨大大小小的其他服務 (自建的 OSS, 或是 cloud provider 提供的 PaaS)。這些服務都會有對應的 SDK，不過要讓每個 developer 都去熟悉所有的 SDK 如何運作與搭配，這對團隊而言是個很大的負擔。因此我這篇背後的設計概念就是:\r\n團隊應該先派出一個先遣部隊 (人不用多，一兩個就夠)，先去嘗試這些基礎服務，替團隊找出最佳的運用與組合方式，再替大家先整合 (封裝) 好，替團隊打造專屬的 SDK。這麼做的目的，不是用自建的 SDK \"取代\" 原生的 SDK (例如本文的 MessageWorker vs RabbitMQ . NET Client)，而是簡化取用 RabbitMQ SDK 的一連串準備動作的過程 (如透過 configuration 取得 RabbitMQ ConnectionURL, 檢查權限與配置等等程序)。",
          "relevance": 0.5090447,
          "partitionNumber": 44,
        }
      ]
    },
    {
      "documentId": "post-2022-04-25",
      "fileId": "0db8eaa31cb946e78d03ba825db0a624",
      "partitions": [
        {
          "text": "所以，關鍵就是上一篇提到的介面設計了，我用 API 涵蓋這個介面，但是實際上介面設計包含 API，以及 API 背後的邏輯跟規則等等相關機制，所以上一篇才會用狀態機 (FSM,\r\nFinite State Machine) 來收斂 API 的結構。這次我要示範的是大部分系統都會有的會員機制。我先用這張架構圖，定義一下，在微服務架構下，所謂的 \"會員\" 這領域的內部服務 (或是有的公司都愛稱呼他 \"中台\")，應該長什麼樣子?\r\n我想像的微服務，不是直接對外開放的 API，而是同時要服務內部其他團隊或是系統的 API 才對。因此需求主要是來自內部其他系統需要怎麼處理 \"會員\" 這 domain 的需求。這些 API 應該要能降低或是取代每個系統直接存取會員資料庫的要求，從\r\ndirect database access 換成 member service API access 才是，因此 API 的設計都針對內部怎麼看待 \"會員\" 的分析，而不是對外的各種功能或是畫面的需求。從上面這張圖來看，會員服務就是中間虛線框起來的範圍。\r\n待會我們就拿上一篇的 FSM 以及分析出來的結果來對應了。這些 API 我力求精簡，有很多需求，其實不一定每個需求都要開新的 API。有些可以合併既有的 API (多呼叫幾次) ，有些是呼叫端可以自己處理或加工，有些是需要呼叫端自己額外建立 DB 或是 local",
          "relevance": 0.5060076,
          "partitionNumber": 3,
        }
      ]
    },
  ]
}

```

而得到這些結果後，再組成這樣的 prompt:

```
## ask
我要導入微服務，全面使用 api 讓我不能再像過去一樣在資料庫 join 不同資料表。有說明這主題的文章嗎？給我條列式的原則，並且列出相關文章的摘要跟連結給我。

## facts
要導入微服務，對團隊而言真的是個高裝檢啊... 從流程，團隊成員的技能，規劃，架構等等，每一個環節都是要配合的。通訊的部分，是直接面對跨越多個服務的環節，會面臨最多的整合環節，也因此我在這邊花費最多的功夫。我就在總結這邊，再重複一次我這篇文章想告訴大家的觀念:\r\n為團隊整合基礎服務\n微服務最不缺的就是各式各樣的基礎建設與框架了 (雖然 .NET + Windows 的選擇仍然是少數 T_T)，不過我還是強調，整合的重要性比選擇框架跟服務還重要啊!\r\n其實只要是分散式系統，或是 cloud native 的架構，你都會面臨大大小小的其他服務 (自建的 OSS, 或是 cloud provider 提供的 PaaS)。這些服務都會有對應的 SDK，不過要讓每個 developer 都去熟悉所有的 SDK 如何運作與搭配，這對團隊而言是個很大的負擔。因此我這篇背後的設計概念就是:\r\n團隊應該先派出一個先遣部隊 (人不用多，一兩個就夠)，先去嘗試這些基礎服務，替團隊找出最佳的運用與組合方式，再替大家先整合 (封裝) 好，替團隊打造專屬的 SDK。這麼做的目的，不是用自建的 SDK \"取代\" 原生的 SDK (例如本文的 MessageWorker vs RabbitMQ . NET Client)，而是簡化取用 RabbitMQ SDK 的一連串準備動作的過程 (如透過 configuration 取得 RabbitMQ ConnectionURL, 檢查權限與配置等等程序)。

## facts
所以，關鍵就是上一篇提到的介面設計了，我用 API 涵蓋這個介面，但是實際上介面設計包含 API，以及 API 背後的邏輯跟規則等等相關機制，所以上一篇才會用狀態機 (FSM,\r\nFinite State Machine) 來收斂 API 的結構。這次我要示範的是大部分系統都會有的會員機制。我先用這張架構圖，定義一下，在微服務架構下，所謂的 \"會員\" 這領域的內部服務 (或是有的公司都愛稱呼他 \"中台\")，應該長什麼樣子?\r\n我想像的微服務，不是直接對外開放的 API，而是同時要服務內部其他團隊或是系統的 API 才對。因此需求主要是來自內部其他系統需要怎麼處理 \"會員\" 這 domain 的需求。這些 API 應該要能降低或是取代每個系統直接存取會員資料庫的要求，從\r\ndirect database access 換成 member service API access 才是，因此 API 的設計都針對內部怎麼看待 \"會員\" 的分析，而不是對外的各種功能或是畫面的需求。從上面這張圖來看，會員服務就是中間虛線框起來的範圍。\r\n待會我們就拿上一篇的 FSM 以及分析出來的結果來對應了。這些 API 我力求精簡，有很多需求，其實不一定每個需求都要開新的 API。有些可以合併既有的 API (多呼叫幾次) ，有些是呼叫端可以自己處理或加工，有些是需要呼叫端自己額外建立 DB 或是 local

## answer

```

拆解動作，各位可以自己嘗試看看。我把上面這段 prompt, 貼到一個完全沒有上下文的 Chat GPT (GPT4), 得到的回答如下:

![](/wp-content/images/2024-03-15-archview-int-blog/2024-03-10-01-24-53.png)

回答很長，我就不貼完整內容了，看起來給了對的 prompt，LLM 就能給出理想的答案了。所以 RAG 的一連串動作，就是藉由 embedding 把整個知識庫的內容，濃縮成上面這段 prompt，最後交給 LLM 推論給出最後的回應 ( answer )，你跟這樣調教過的 GPTs 對談，就會有他好像懂很多東西的錯覺了。要擴大 GPTs 的知識範圍，RAG 是個很有效率的做法，不但能自訂知識庫，內容也能即時更新，更重要的是你不需要重新訓練語言模型。這對 LLM 的大規模使用有很大的幫助。





# 3. 實作技術選擇

原本，我都做好心理準備了。上面的 RAG 操作，搞懂後拆解出來的步驟都不難，都打算自己用 Semantic Kernel 動手刻一個簡單的 API 來用，結果在查 SK 有沒有實做單機版的 Semantic Memory 時，意外找到了另一個 Microsoft 開源的專案: Kernel Memory.

看了一下，我想做的功能他都做出來了啊，於是寫到一半的 code 就收起來了，轉來研究這個 open source project。這是套基於 Semantic Kernel 開發出來的獨立服務版本，提供多種存取他的方式 (有 REST API, WebClient SDK, Semantic Kernel Memory Plugins, 也有 Serverless SDK)，服務本身也提供多種部署方式 ( 獨立服務, 或是 embedded 在你的專案內 )。後端的儲存、向量搜尋、以及內容檢索的 pipeline 都能選擇現有成熟的服務，算是很完整的選擇了，大推。

我的使用量不大，而且資料量也不多，我的目的是要體驗完整 RAG 的流程該踩過哪些步驟，因此我的選擇是:

1. 單機部署，提供 REST API 讓 Chat GPT 來呼叫
1. 服務本身我就不想再拆成資料庫跟處理檔案的 worker 了，我選擇全部塞進單一 container 的配置，用 in-memory 向量資料庫 (就只是 c# 簡單的向量計算 + Linq 而已)，資料就直接放 file system。
1. 我拔掉了異動檔案的 API，讓他只是個 read-only 的 container, 我的部落格是用 GitHub Pages, 異動一定會觸發 CI/CD 重新 build 整個靜態網站，我打算整合這流程，文章有異動再重新 build container, 重新部署就好。



## 3-1, Kernel Service

再讚嘆一次，追完他的 source code 發現這真的是好東西，我先介紹我的主軸: 部落格文章 RAG 檢索後，再回頭來聊聊 Kernel Memory 這專案設計精巧的地方。

先看看 Kernel Memory 原生提供的 REST API Spec:


我拔掉我不需要的，只剩下:


當我把我的部落格文章都塞進去後，我可以這樣使用:


搜尋:


搜尋:


詢問 (RAG):


詢問 (RAG):


看來效果還不錯，這樣的資料量跑起來也不算慢... 部署上 Azure App Service 後，下一步就是 GPTs 了..

## 3-2, 安德魯的部落格 GPTs




## 3-3, 我該提供自己的 Web UI 嗎?





## 3-5, 向量資料庫 - 基本結構




## 3-4, RAG 檢索的安全問題






# 4. 進階應用




# 5. 總結



