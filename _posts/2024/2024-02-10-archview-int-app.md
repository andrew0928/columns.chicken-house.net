---
layout: post
title: "替你的應用程式加上智慧! 談 AI 應用程式的開發"
categories:
- "系列文章: 架構師觀點"
tags: ["架構師觀點","技術隨筆"]
published: false
comments_disqus: false
comments_facebook: false
comments_gitalk: true
redirect_from:
logo: 
---

上一篇文章 [架構師觀點 - 開發人員該如何看待 AI 帶來的改變?](/2024/01/15/archview-llm/)，展示了我嘗試的 GPTs 整合應用，實現了讓 AI 助理的嘗試，我開始真的可以用自然語言就完成整個購買流程的操作了。過程中，AI 也幫我 "腦補" 了部分我 API 沒有提供的功能 (指定預算跟購買條件，AI 自動幫我思考購買組合)。這結果其實比我預期的還理想，完成之後，我開始探索接下來的這兩個問題:

- 未來的應用程式，會怎麼運用 "AI" ?
- 未來軟體開發的流程與角色，會變成甚麼樣貌?

因此，這篇我就要面向應用程式的開發面，來探討該怎樣把 "智慧" 加到你的應用程式內。雖然 LLM 還有很多缺點，但是你應該開始把 LLM 當作 "人" 來看待了，溝通的方式都要把它當作 "人" 的方式溝通 (因此要善用 prompt, 而不是 function + parameters)。這其實跟傳統的軟體開發結構完全不同，也是我這篇想繼續往下挖的主題。

上面我列的兩個問題，一個是未來的軟體執行方式，改變的是使用者使用軟體服務的習慣；另一個是未來軟體開發的架構，流程與分工，改變的是軟體開發領域的生態，包含服務，結構，開發框架，流程，工具等等，預期都會被 AI 翻了一輪。改變是必然的，不確定的是會怎麼變? 因此，我決定延續 "安德魯小舖" 這 PoC, 假設這是五年後的服務呈現的樣貌，那麼這過渡期間會如何發展? 如果五年後是這樣，那麼現在大家使用的工具與知識會有什麼變化?

<!--more-->


>
> 說在前頭，我目前仍然是個 AI 的門外漢，這篇是野人獻曝，分享我自己摸索過程而已。我擅長在摸索過程中盡可能搞清楚全貌，再來學習會比較精準有效率。過年期間 K 了很多文章，總算搞清楚 Open AI / Semantic Kernel 在幹嘛。文內的敘述有錯的話歡迎留言通知我，感謝~
>

# 1, "安德魯小舖" 的進化


雖然完成了 "安德魯小舖 GPTs" 的 POC, 但是我仍然這不會是短期內 ( 1 ~ 3 年內 ) 大量運用 AI 的應用程式樣貌。把應用程式 Host 在 Chat GPT 上，還有很多不夠成熟的地方:

* 很容就踩到使用量的限制
* 並非每個消費者都有 Chat GPT plus 訂閱
* Chat GPT 回應的速度跟可靠度都還不及

這些對線上交易而言都不是個很好的選擇，我相信 Open AI 會持續改善這些問題，不過算力珍貴 (現在是各大廠的必爭之地)，也不可能一夜之間改善，我覺得漸進式的在現有應用程式內加入 "智慧"，先從最需要 "智慧" 的環節改變，才是合理的發展路線。

於是，既然可行性已經確認了，接下來就往產品發展的方向來思考了。我拆解了 "應用程式加入智慧" 這願景，拆成這四個階段，重作了一次這題目，作為這篇 demo 的主軸。開發細節跟程式碼，這篇實在寫不下，我就先截圖給大家體會，同時先提供 github repo, 有興趣的可以先看, 或是等我下一篇文章..

1. 尚無智慧, 只提供 **標準的操作模式**  
(這邊我用了 console app + 選單的操作, 模擬上古時代功能型手機的那種操作體驗。如同那些不友善的 chetbot 應用一樣，你只是透過 IM 的外殼，來執行選單的操作而已。我拿這當作對照組，各位可以自行替換成 MVC 或是其他操作介面。

[![](/wp-content/images/2024-02-10-archview-int-app/2024-02-17-02-00-27.png)](/wp-content/images/2024-02-10-archview-int-app/2024-02-17-02-00-27.png)

1. 結帳時確認: **從操作意圖評估風險**  
在關鍵功能 (我的定義: 結帳) 執行時，能靠 LLM 歸納與推理的能力提供個人化的建議，找出各種不是和交易執行的問題或是風險。除了 rule based 的規則檢查，應該有一個關卡是由 AI (這邊指 Generative AI, 不是 Machine Learning AI) 來進行前後文的邏輯推演，找出 "常識" 裡不合理的地方，提醒使用者。

[![](/wp-content/images/2024-02-10-archview-int-app/2024-02-17-02-03-08.png)](/wp-content/images/2024-02-10-archview-int-app/2024-02-17-02-03-08.png)

```
assistant > 結帳前有任何要求可以跟我說，若無我將替您結帳 (直接輸入或是 ENTER 跳過)
小孩10歲生日派對要用的, 請附上卡片跟氣球給我, 謝謝
copilot > user: 我要進行結帳前確認
我要開始結帳，沒問題請回覆 "OK: "，有注意事項請回覆 "HINT: "。
其他建議可以在回覆之後接著說明。
copilot > user: 以下是我購物車內的清單:
- [1] 18天台灣生啤酒 355ml, 單價 NT$65.00 x 5 件
- [2] 可口可樂R 350ml, 單價 NT$18.00 x 10 件
預估結帳金額: NT$453.00
copilot > user: 購買註記:
- 小孩10歲生日派對要用的, 請附上卡片跟氣球給我, 謝謝
..............................................................
助理店長提醒:
HINT: 根據您提供的購物清單，您選購了含酒精的「18天台灣生啤酒」，請您確認是否有符合法律規定的年齡限制（需年滿18歲），並請留意避免酒後駕駛。

另外，由於您提到購買這些商品是為了小孩10歲的生日派對，請確認是否有成人將負責管理並確保啤酒不被未成年者飲用。您購買的「可口可樂」數量較多，請注意不要過量攝取含糖飲料。

若這些商品確實是您所期待的，且您已經遵守相關法律規範與健康指引，就可以開始結帳程序。至於您提到的卡片與氣球，請讓我確認我們是否有這項服務可供提供。稍後將給您進一步的訊息。

assistant > 您可以決定是否修正購買內容喔，是否要直接結帳 ( Y / N )?
y
info > waiting for payment...
assistant > Checkout completed successfully. your order number is: [1]

command >
```

> 如果看不清楚截圖, 我貼上文字版。結帳時我彙整了摘要內容，組成 prompt 問 LLM, 請他告知有無需要店長注意的地方。LLM 聯想到給小孩 10 歲 (未成年) 生日派對用的飲料買了啤酒，提醒客人法令規定。


1. 操作過程中全程輔助: **從操作歷程判定使用者的狀況，即時提供操作建議**  
範圍再擴大一點，應用程式可以在背後持續收集使用者的行為，不斷地送給 LLM (就像 APP 不斷地在跟 Chat GPT 講話一樣), 讓 LLM 回報使用者的行為是否有需要留意或是提示 (最典型的案例就是 GitHub Copilot, 用過的都知道我的意思)。比起 (2) 是在 "結果" 一次告訴你，這模式更貼近使用者的操作，在過程中就直接提醒你了。

[![](/wp-content/images/2024-02-10-archview-int-app/2024-02-17-02-09-41.png)](/wp-content/images/2024-02-10-archview-int-app/2024-02-17-02-09-41.png)

```
Login / Register First:
- username:     andrew
- password:     *********
Hello andrew(1), Welcome to Andrew's Shop!

        0. show me (this menu)
        1. list products
        2. shopping cart commands
        - 21. show my items
        - 22. add items (patterns: 22 [pid] [qty])
        - 23. remove items (patterns: 23 [pid] [qty])
        - 24. empty my cart
        - 25. special: add items with budget (patterns: 25 [pid] [budget])
        3. checkout (patterns: 3 [payment-id])
        4. my account info
        5. exit

command > 22 1 5
assistant > 商品 [1] x 5 件, 已經加入您的購物車了。
copilot > user: 我已進行操作: 我在購物車內加入了 5 件商品 (商品 ID: 1, 18天台灣生啤酒 355ml)
........copilot > function call: ShopFunction_AddItemToCart(productId: 1, quanty: 5)
.....
copilot notify > OK


command > 23 1 5
assistant > 商品 [1] 已經從您的購物車中移除了 5 件.
copilot > user: 我已進行操作: 我在購物車內移除了 5 件商品 (商品 ID: 1, 18天台灣生啤酒 355ml)
....copilot > function call: ShopFunction_RemoveItemToCart(productId: 1, quanty: 5)
..
copilot notify > OK


command > 22 1 5
assistant > 商品 [1] x 5 件, 已經加入您的購物車了。
copilot > user: 我已進行操作: 我在購物車內加入了 5 件商品 (商品 ID: 1, 18天台灣生啤酒 355ml)
........copilot > function call: ShopFunction_AddItemToCart(productId: 1, quanty: 5)
...............................
copilot notify > HINT: 您剛剛加入了5件含有酒精的商品，根據法律規定，請確保您的年齡符合購買酒精飲料的法定限制，並請注意不要酒後駕車。如果您有任何疑問或需要其他幫助，我隨時在這裡協助您。


command > 23 1 5
assistant > 商品 [1] 已經從您的購物車中移除了 5 件.
copilot > user: 我已進行操作: 我在購物車內移除了 5 件商品 (商品 ID: 1, 18天台灣生啤酒 355ml)
....copilot > function call: ShopFunction_RemoveItemToCart(productId: 1, quanty: 5)
...
copilot notify > OK


command > 22 1 5
assistant > 商品 [1] x 5 件, 已經加入您的購物車了。
copilot > user: 我已進行操作: 我在購物車內加入了 5 件商品 (商品 ID: 1, 18天台灣生啤酒 355ml)
......copilot > function call: ShopFunction_AddItemToCart(productId: 1, quanty: 5)
............
copilot notify > HINT: 我注意到您已經多次加入與移除同一件商品，是否您遇到了一些選購上的困難或有其他疑問需要幫忙解決 ？我隨時都準備協助您。


command > 23 1 5
assistant > 商品 [1] 已經從您的購物車中移除了 5 件.
copilot > user: 我已進行操作: 我在購物車內移除了 5 件商品 (商品 ID: 1, 18天台灣生啤酒 355ml)
.....copilot > function call: ShopFunction_RemoveItemToCart(productId: 1, quanty: 5)
..
copilot notify > OK


command >
```

> 這次我啟用了 copilot, 每個步驟都會在背後組一段 prompt, 告知 LLM 客人在幹嘛。如果 LLM 察覺客人需要協助，就會提醒店長要去關心客人了。
> 我故意重複把同一件商品加入購物車，又移除。果然第三次後 LLM 就提醒我了，是否碰到選擇困難 XDDD


1. 全自主的助理店長: **全對話式的操作**  
最理想的方案，才是像我在 "安德魯小舖" GPTs 展示的一樣，完全都透過 Agent 的介面，用自然語言溝通 (包含語音等等媒介) 來驅動的應用程式。不過，這個 Agent 不一定要是掛在 Chat GPT 這平台上的 GPTs，有更多適合 Hosting 這個 Agent 的方式。我認為較有可能能的發展，是在主流的使用者端作業系統 (目前局勢看來，就三大終端系統: windows / android / iOS ) 提供相關服務，讓應用程式 "掛" 上去，並且由 OS 提供 Agent 的存取介面。

> 這段，就是我上一篇 "安德魯小舖 GPTs", 我就不再重複了，你有幾種方式可以體驗 [安德魯小舖 GPTs](https://andrewshopoauthdemo.azurewebsites.net/swagger/index.html):
> 1. 懶人包, 可以直接看完整 [對談紀錄](https://chat.openai.com/share/836ef17f-3f70-47f1-9a36-eb56d9acc4c1)。
> 1. 技術細節，可以直接看我這次開出來的 [購物網站 API 規格](https://andrewshopoauthdemo.azurewebsites.net/swagger/index.html)
> 1. 實際體驗 [安德魯小舖 GPTs](https://andrewshopoauthdemo.azurewebsites.net/swagger/index.html), 只要你有 Chat GPT Plus 訂閱，點這個連結就可以體驗了。我只是實驗性質，API 目前架設在 Azure App Service 下，沒有 HA，隨時會關掉。資料都是存在記憶體內，服務重啟就會清空。帳號註冊登入只是個流程，只看 username，密碼亂打都可以過。


其實，這些發展的脈絡，是我自己先有個構想，嘗試與驗證的過程中，看到這篇文章，才發現我想的發展脈絡，其實 Microsoft 已經整理好並且寫成 Guideline 了 (不過 Microsoft 跳太快，直接接到 Semantic Kernel 了，我想要多補充中間的結構)，我就借用一下:

![](https://learn.microsoft.com/en-us/semantic-kernel/media/types-of-agents.png)
> 文章: [What is an agent?](https://learn.microsoft.com/en-us/semantic-kernel/agents/?source=docs&WT.mc_id=linkedin&sharingId=AZ-MVP-5002155)



文中這張圖表，對應 Agent 發展的幾個階段，正好可以跟我想像的智慧化發展階段對上:


1. **Chatbot**:  
這階段訴求是 "對談"，透過 IM 來與 Agent 互動的形式是重點。不過這階段只有單純的對答，Chatbot 在過去幾年有很多討論，不過都在強調跟各個 IM 平台的整合與開發。我就當作對應到我的第一階段 (**文字介面: 最基本的選單式的操作**)。

1. **RAG**:  
RAG 是個檢索的方式，可以讓 LLM 擴充他的 "知識庫" 的做法。不需要重新訓練語言模型，也不需要把所有的 "知識" 都塞進 prompt 內就能達到對等的效果。RAG 能將 LLM 能檢索的範圍擴大到資料庫層級。詳細的過程我下一段再說，在這階段，透過 Agent 用對話來檢索正確的知識，是主要的應用。

1. **Copilot**:  
這個階段, Agent 應該要能 side-by-side 協助 user 完成任務，其實就是對應到我想的安德魯小舖第三階段 (**從操作歷程判定使用者的狀況，即時提供操作建議**)，跟著使用者一步一步的操作，隨時給出適當的操作建議。Agent 應該要掌握使用者操作的過程 (APP 要在背後送操作資訊給 Agent)，適時的從旁跟著使用者，引導他正確完成任務。在這階段，操作還是都靠使用者自己完成，只是有了正確的提示，再搭配 UI 操作的整合 (如果有的話)，使用的體驗就會大幅提升。

1. **Fully autonomous**:  
這個階段，Agent 應該要有 "自主運作" 的能力了。而所謂的自主運作，就如同我上一篇文章第一段，示範的 "安德魯小舖 GPTs" 一般，你只要用自然語言跟他對談就夠了，Agent 會幫你完成你想要做的事情。這背後，最主要的突破，是要讓 LLM 有能力呼叫你的 API 完成任務的相關機制。這就是對應到我講的第四階段 (**全對話式的操作**)。

正好，這四個階段，我的 POC 都有點到了，範例程式可以體驗一下。我的目的是概念驗證，因此為了降低我腦袋的負荷，我不擔心的工程細節我都跳過了。我在 .NET Conf 2023 那個場次講的 "降級" 思考，就是這麼一回事。

對我而言，很多工程細節，是開發過程中一定要克服的，那些事情是 "把事做對"，但是 POC 階段，更重要的是弄清楚該不該做? 關鍵是 "做對的事"。這是我選擇降級，忽略掉我不擔心的環節，把心力放在探索上面的原因。

因此，這邊我會用到的技術或是平台，有這些:
1. 開發框架: .NET 8, C#, Microsoft Semantic Kernel (我用 1.3.0)
1. API 我採用 Azure Open AI, 用的是 GPT4 model (我用 1106 preview)
1. Chat GPT plus ( GPTs + Custom Actions )

而實做過程中，有些我認為該用，但是暫時被我忽略沒往下挖的部分:
1. Microsoft Semantic Kernel 的 prompt template, planner, semantic memory, kernel memory (這兩個不一樣...)
1. Open AI 的 Assistant API
1. 改用能在 local 運行的 LLM ( LLaMa 2 chat 70B )





# 2, 應用程式要加上 "智慧" 的設計框架



我是 AI 大外行，資料分析、深度學習也不是我的專長，因此我也沒辦法討論模型訓練等等很深入的 AI 議題；不過我擅長的是軟體開發，我擅長用程式碼正確的實現領域模型，因此我在過去一年都在想的是: 如果 LLM 越來越成熟，那我該如何好好運用他? 因此，我假定已知 LLM 的這些問題 (例如幻覺，不可預測，運算資源... etc) 三年後都會被解決，那三年後我準備好擔任那個世代的架構師了嗎?

所以，這個段落，我特別想花點篇幅聊一下，我覺得現在是改變想法的轉折點，是該投入時間好好研究了。在過去 (尤其像我這類) 在軟體開發領域的資深人員，往往所有事情背後都會被拆解成明確的規則，流程，演算法，資料結構等等，然後試圖在所有問題背後都能理出一個脈絡，所有的 input 跟 output 都應該是明確的可被預測的... 但是 AI 出現後 (尤其是生成式 AI)，這一切開始沒有這麼 "明確" 了。連很多 AI 的專家其實也猜不透 LLM 背後運行的邏輯是什麼，只知道餵給他足夠的訓練資料，產出的模型能回答出理想的答案而已。資料的複雜度，已經被轉移到模型的複雜度，然而 AI 專家們自己也無法掌握模型背後的運作方式..

在這基礎的觀念被打破的時候，你的 "傳統" 應用程式，該如何加入這些 "不可預測" (你無法預期使用者會問你什麼怪問題)，卻又要精準執行 (你要解讀使用者的需求後，呼叫對應的 API，給對應的參數) 系統功能之間的矛盾，就變成這些資深人員需要思考的事情了。我也無法搞清楚模型背後在幹嘛 (我是 AI 外行人啊)，不過我至少得弄清楚它的特性，才能決定應用程式架構該怎麼設計。

我參考了 Semantic Kernel 的框架設計，也參考了 Open AI 的 Assistant API，實在很佩服訂出這些介面規格的人。它們把背後 AI 如何運作這件事，抽象化的非常清楚明確。起初我看了一堆 SK 的文章，看的一頭霧水，我決定暫停看 code，趁著過年好好地看完一些文章，了解流程後再回頭看 code 就恍然大悟了。

我強烈建議各位也花點時間理解這背後的知識，會很有幫助的。這段我花一點篇幅解讀一下它們背後的想法，你會清楚你該如何把它 (人工 "智慧") 放到你的應用程式內。


## 2-1, LLM + 短期記憶 (聰明)

開始之前，先來看看對照組 (完全跟 AI 無關的應用)。典型的傳統應用程式，不外乎分成 UI / Domain / Data 三層.. 我就簡單的畫就好了:

![](/wp-content/images/2024-02-10-archview-int-app/2024-02-16-00-07-52.png)
> 圖 1, 標準的應用程式


再來看看最基本的 LLM, 這邊指的 LLM，只是純語言模型，沒有任何狀態。基本上就是餵給他一段提示 (prompt), 他就會給你一個回應。你給第二段提示, 他是不會記得上一次你問了什麼的，除非你拿著第一次的提示 + 第一次的回答給他，他回答就會比第一次理解你的意圖了。

這邊關鍵是 LLM 有足夠的語言理解能力，我就當作他他真的聽懂我的意思了。基本上你可把它當作正常人來對談，只是他有的只是通識，或是訓練資料內的公開知識。他的記憶力也不好，講完就忘了 (無狀態)，除非你每次都要重複前面的對話內容；同時他也不見得有你需要的特定領域，或是公司內部的知識，這些都需要額外處理。

最關鍵的還是他的理解能力夠不夠強，他的記憶力差這件事很好解決，就是每次都給他完整 (或是篩選過的) 對談的紀錄 ( Chat History ), 這時, chat history, 對 LLM 而言就是維持短期記憶的機制

![](/wp-content/images/2024-02-10-archview-int-app/2024-02-16-00-15-56.png)

> 圖 2, LLM + Chat History, 有短期記憶能力的 AI

應用到安德魯小舖，短期記憶就是客人進商店後到結帳這段過程中的資訊..



## 2-2, RAG + Embedded, 記憶與檢索 (智慧)

當你累積的知識變多，不再能每次起始對談都把那堆知識塞進 prompt ( token 很貴的... ), 你就需要更有效率的做法了。人類在求學階段念了很多書，往後的日子會不斷的把過去學習的 "知識" 拿出來應用，這就是 knowledge。這些 knowledge 可不是原封不動一字不漏的存在腦袋，然後在腦袋裡做全文檢索... 而是你會把知識分類 & 消化，需要時你會去 "聯想" 找出關聯的知識出來用。

這過程，就是 text embedding, vector storage 以及 RAG 的運作過程。讀書的過程就是理解，對應到 AI 的處理機制，就是靠 LLM 來做 text embedding，也就是把知識 (一段文字) 向量化，靠 LLM 解讀了解後，將這段文字在幾千個維度的空間內標示一個向量來代表，儲存在 vector storage。每個維度代表一個知識領域，這維度的投影就代表這段知識在這個領域的關聯度有多高。

事後你問 LLM 問題，LLM 一樣把問題 (prompt) 用 text embedding 解讀成向量，這時只要拿著 input 的向量，到向量資料庫內做基本的過濾，加上搜尋相近的片段 (就是兩個向量之間的 cos 值，越相近數字越接近 1.0 ), 檢索出來的結果當作上下文，再交由 LLM 彙整後回傳，這就是 AI 如何在大量知識庫內快速檢索的過程，也就是 RAG (Retrieval Augmented Generation,擷取增強生成) 的運作原理。

![](/wp-content/images/2024-02-10-archview-int-app/2024-02-16-00-17-29.png)

> 圖 3, 加上 Knowledge 知識庫, LLM 開始擁有長期記憶

其實這很符合人腦在運作的流程啊，講白了就是 "聯想" 並且從記憶內找出知識的能力。這些東西被系統化的結果，就是 AI 的長期記憶。應用到安德魯小舖，就是店長的 SOP 標準流程, 知識庫, FAQ, 或是服務紀錄等等。能力表現好的店長，可以在腦袋裡快速地檢索，立刻聯想到相關案例，當下回答客人問題或是給出理想的建議。這過程做得越到位，表現的結果就是越稱職。

參考: [Retrieval Augmented Generation using Azure Machine Learning prompt flow](https://learn.microsoft.com/en-us/azure/machine-learning/concept-retrieval-augmented-generation?view=azureml-api-2&WT.mc_id=linkedin&sharingId=AZ-MVP-5002155)


### Skills, 運用技能 (才能)

AI 終究不能只出一張嘴，也要會做事才行，這樣才能真正替你分攤任務。這是 Agent 很重要的關鍵，也是 LLM 開始跨入實用階段的重要突破。我就是想通這段，才搞定 "安德魯小舖 GPTs" 的。在搞懂 LLM 怎麼呼叫外部 API 前，先回想一下 "人" 是怎麼學會使用技能的..

人經過學習，練習，最終會掌握一些技巧 (Skill)；而當有人對你做出請求的時候，他是用自然語言告訴你的... 你必須 "聯想" 要完成請求的話，需要用那些你學過的技能? 這過程其實跟 RAG 有點類似，但是 RAG 只讓你 "找到" 符合的知識，這邊還要正確的 "執行"。

因此 Skill 還有後面這段，當 LLM 已經決定哪個 "Skill" 能解決問題後，接著就有其他步驟要進行了。例如做衣服，當你學過裁縫後，別人請你做衣服，你就會根據你學到的技巧，你知道你需要有對方的身材尺寸才能做好衣服。於是你會去想辦法得到這些資訊 (直接丈量，或是查顧客紀錄等等)，也許這過程又是另一個 Skill。不斷重複這過程，你終究可以準備妥所有必要資訊。

這時，Skill 的執行，就像是 API 呼叫一樣了，LLM  根據 input, 推測了該使出哪個 Skill (API)，需要那些附加資訊 (Parameters)，最後只要施展技能 ( Function Call ) 就完成了。如果技能施展後有些成果 (API return value)，LLM 會把它當作上下文，彙總成白話文回答給你，這就是 LLM 幫你做事的過程。

對應到大家熟悉的 Chat GPT, GPT4 現身後，他能搜尋 internet, 他能執行 plugins, 都是靠 function calling 的能力。我上一篇文章介紹的 "安德魯小舖 GPTs", 就是我把線上購物的 API，掛上 GPTs Custom Action, 賦予 GPTs 代替我操作購物車跟瀏覽商品的能力，最後我就能只靠一張嘴就要求他幫我完成整個購物過程，同時也完成我各種刁難的訂單內容安排的要求。

這過程很重要，這也是 LLM 開始有 "執行任務" 能力的關鍵。過去語言理解能力不足的時候，要講人話都很困難了，哪有辦法還能理解出這段話該呼叫哪個 API，該如何長出必要參數? 而在語言能力到達某個水準時 ( GPT4 達到這水準了 )，這門檻跨過了，就開始有透過對話執行任務的能力。

> 有興趣的話，可以看一下 Open AI 這篇，很有條理地說明了 [Function calling](https://platform.openai.com/docs/guides/function-calling) 的過程。

因此，學習到的 Skill, 應該要能像 Knowledge 一樣，學過就被註冊記錄下來。每個 Skill 也有白話描述他是做什麼用的 (說明書?)，也有參數定義跟說明，以及傳回值的定義跟說明。而組成這一切，就是靠 LLM 的語言理解能力，以及自然語言與結構化資訊轉換的能力。

![](/wp-content/images/2024-02-10-archview-int-app/2024-02-16-12-37-47.png)


<!-- 

> 科普: 其實這段，不知道大家有沒有聯想到? 目前已經很多工程師，靠 Chat GPT 寫 code 了，你需求用白話文輸進去，Chat GPT 就能給你一段有模有樣的 code, 其實就是運用了上面的能力，只是產出的是 source code 而已。如果再加一段 "AI 的助手"，幫你把這段 code 在安全的 sandbox 編譯，執行，直接給你結果，其實就是上面在做的事情了。這在 Chat GPT 裡稱作 "code interpreter" ..  
> 當這技術成熟到某個程度，成本低到某個程度時，軟體開發的流程就會再度被翻一輪了。到現在為止，我們談的都還是 "怎麼寫程式"，"怎麼寫智慧的程式" .. 等到這階段，已經是不需要寫程式的時代了。不過看來離我還很遠，可行性我覺得不遠了 ( 5 ~ 10 年內應該看的到 )，但是效率我覺得還是比不上產生程式碼再編譯執行，即使自動化也是 -->


挖到這邊，LLM (大腦) + Chat History (短期記憶) + Knowledge (長期記憶、知識) + Skill (技能)，整個整合好之後，這整組服務就能對自然語言的輸入，做出正確的回應，或是執行正確的動作了。


### Persona 人格, 個性, 個人化

最後，我把沒提到的環節補完吧。Prompt Engineer 都會提到的技巧 - Persona, 角色設定，我把他補上去了:

![](/wp-content/images/2024-02-10-archview-int-app/2024-02-16-00-36-30.png)

不知道有沒有人記得這部電影? MIB... Will Smith 把人的記憶消除後 ( reset 記憶 )，會掰一段人物設定，跟時空背景。被消除記憶的人聽完就會認為他是那樣的人... 於是就乖乖地扮演這角色了。LLM 先天就沒有狀態 (記憶)，所以這些人格設定，反而是你 "必須" 給他的。

通常會有兩個部分，一個是你要告訴 LLM，Agent 是什麼角色，該做什麼，不該做什麼，稱作 Persona, 或是 GPTs 的設定內的 Instruction。而另一段是告訴 LLM 你自己是誰，想要聽什麼樣的資訊，GPTs 會盡量講你想聽的話，這在 Chat GPT 內是擺在 "Customize ChatGPT" 這功能內。

我的想像，如果以後主要的 LLM 是由作業系統來提供 (就前面提到, windows / android / iOS 這些廠商), 而這些個人化的設置, 就有更多的可能性了。你的瀏覽紀錄，行事曆，聯絡人等等，可能都會是本地端 RAG 檢索的來源，這邊就是廣義的 "個人化" 了。在圖上我用 Personal Information 表示。

不過，這些都還不是我這次要探索的範圍，因此我的 demo 都略過了，只是簡單地把這些資訊，用有限的文字描述，直接放在 prompt 裡面。你可以想像我把這些都簡化成你跟陌生人聊天，前幾句話都是 "自我介紹" 那樣而已，就足以應付我目前的情境了。


### 小結

寫到這邊，不知道你有無看到重點? 這邊我都在理解怎樣在軟體架構設計內，合理的把 AI 也放進去的思路。除了 LLM 最核心，最難理解 LLM 怎麼能搞的懂自然語言之外，其他都是基於這核心，用很單純的系統化做法把外圍的資訊都串起來。你會發現沒有 LLM，這一切都沒有用了。

我在寫這段的時候，我刻意避開了不必要的實做細節，大致都只談到結構上該怎麼做而已。實做上大致就分兩派，一種是在 cloud 通通都幫你做好，你只管拿 APIKEY 呼叫 API 就好的方式 (PaaS), 例如 Azure Open AI 就屬於這種。另一種是把上述的處理結構都抽象化，變成一個開發框架，讓你自己去組合你要的元件 (你要哪種 LLM，哪種向量資料庫 ... 等等)，我多次提到的 Microsoft Semantic Kernel, 或是 Lang Chain 就屬於這種。

當初我就是沒先想通這一段聊的內容，就直接看 SK 的開發文件，最後搞得一頭霧水.. 現在再回過頭來看這張圖，突然之間都清楚了:

![](/wp-content/images/2024-02-10-archview-int-app/2024-02-17-01-49-13.png)

> 來源: [Want to build a Copilot for your app? Semantic Kernel & Prompt Flow for Beginners](https://techcommunity.microsoft.com/t5/healthcare-and-life-sciences/want-to-build-a-copilot-for-your-app-semantic-kernel-amp-prompt/ba-p/3902524)



看到這裡，挑一個合適的開發框架 (我挑 Semantic Kernel), 它會讓你的應用程式有很好的擴充與替換的空間。我後面會做的示範，就是從 console-ui 版本的線上商店，逐步加上上述功能，重新做一次 .NET console app 版本的安德魯小舖。



# 3, Demo


## 1-1, Console UI

原始版本的 source code: 請參照 AndrewDemo.NetConf2023.ConsoleUI 這個 project ( master branch )
https://github.com/andrew0928/AndrewDemo.NetConf2023/tree/master/AndrewDemo.NetConf2023.ConsoleUI

Code 我就不多做說明了，跟 GPTs 那個版本用的是一樣的 Core, 只是直接拿來建立 ConsoleUI 而已。
基本結構很單純，通過帳號密碼 / 帳號註冊的流程確認身分後，接著就是一個命令讀取 => 執行的迴圈而已，每個命令都有一個對應的 delegate ConsoleProcessor 來對應。
這些 Command 就實做了基本的線上購物的功能，有興趣可以直接參考 source code.

為了節省篇幅，我就截圖說明使用的模式，目的是讓大家能想像後續追加的功能:


(主畫面)


大致上就像這樣，主選單:

```text

0. show me (this menu)
1. list products
2. shopping cart commands
- 21. show my items
- 22. add items (patterns: 22 [pid] [qty])
- 23. remove items (patterns: 23 [pid] [qty])
- 24. empty my cart
- 25. special: add items with budget (patterns: 25 [pid] [budget])
3. checkout (patterns: 3 [payment-id])
4. my account info
5. exit

```

輸入前面的數字，就能執行該指令。有些指令有附帶參數，就按照最後面括號說明的 pattern 來輸入就好。

例如下列的情境:

- 列出商品清單
輸入指令: 1
輸出訊息:
```
command > 1
assistant > 您好, 以下是我們店裡有賣的東西...
- 1     18天台灣生啤酒 355ml    NT$65.00
18天台灣生啤酒未經過巴氏德高溫殺菌，採用歐洲優質原料，全程0-7°C冷藏保鮮，猶如鮮奶與生魚片般珍貴，保留最多啤酒營養及麥香 風味；這樣高品質、超新鮮、賞味期只有18天的台灣生啤酒，值得您搶鮮到手! (未成年請勿飲酒)

- 2     可口可樂R 350ml NT$18.00
1886年，美國喬治亞州的亞特蘭大市，有位名叫約翰‧潘伯頓（Dr. John S. Pemberton）的藥劑師，他挑選了幾種特別的成分，發明出一款美味的糖漿，沒想到清涼、暢快的「可口可樂」就奇蹟般的出現了！潘伯頓相信這產品可能具有商業價值，因此把它送到傑柯藥局（Jacobs' Pharmacy）販售，開始了「可口可樂」這個美國飲料的傳奇。而潘伯頓的事業合夥人兼會計師：法蘭克‧羅賓森（Frank M. Robinson），認為兩個大寫C字母在廣告上可以有不錯的表現，所以創造了"Coca?Cola"這個名字。但是讓「可口可樂」得以大展鋒頭的，卻是從艾薩‧坎德勒（Asa G. Candler）這個具有行銷頭腦的企業家開始。

- 3     御茶園 特撰冰釀綠茶 550ml       NT$25.00
新升級!台灣在地茶葉入，冰釀回甘。台灣在地茶葉，原葉沖泡。如同現泡般的清新綠茶香。
```

- 放 5 瓶綠茶 (id: 3) 進購物車
輸入指令: 22 3 5
輸出訊息:
```
command > 22 3 5
assistant > 商品 [3] x 5 件, 已經加入您的購物車了.
```


## 1-2, with Checkout Assistant

接下來，開始要加入第一個需要 LLM 輔助的功能了。我期待 assistant 能在結帳時，額外檢視購買的商品是否有注意事項需要提醒。這邊的提醒，我希望 LLM 能用他 "博學多聞" 的能力，提示產品經理或是開發團隊沒有想到的功能，或是能有效率地從產品 SOP 文件，或是客服問題處理紀錄來檢索，預防一些會造成客訴的訂單，由 LLM 提前預警。

舉例來說，商品可能沒有正確標示購買資格，而 LLM 有更多機會從商品描述，與店長職責規範內，找出需要提醒的事項。範例中的商品包含生啤酒，商品並沒有特定的欄位標記 "含酒精"，也沒有任何一行程式碼標記 "須年滿十八歲"，或是 "酒後不開車" 等。而結帳前若能將購物車內容，彙整成一段說明交給 LLM ( role: user ), 而這個 chat session 若有事先設定 system prompt 交代店長職責，LLM 就能像個真正的店長一般，親切的提醒客人注意事項。

為了達成這目的，我做了三件事:

1. 系統啟動之初，就正確的設定 system role 的 prompt。
就如同大家在用 Chat GPT, 第一句話都會告訴 AI 你現在是誰，要做什麼事.. 如果你在設計 GPTs, 你也會先寫一段 instructions 來敘述這 GPTs 的人物設定..

我的 system role prompt 如下:

```
你是 "安德魯小舖" 的助理店長, 負責協助引導每個來商店購買的客人順利結帳。
主要任務有三類:
1. 結帳前的確認
2. 選購過程的操作過程關注
3. 回應客人的問題或是操作要求 (可呼叫 function call)

以下是這三類任務的流程說明:                

結帳前請檢查下列項目:
1. 客人購買的東西是否適合他的期待? 請協助客人確認購買清單。
2. 客人的購買行為是否安全? 請協助客人確認購買行為。有些商品有法律限制，或是有可能對客人造成危險。
3. 客人的購買行為是否合理? 請協助客人確認購買行為。有些商品可能有更好的選擇，或是有更好的折扣。
4. 檢查 FAQ 清單
5. 確認方式: 客人提示訊息會用 "我要進行結帳確認: XXX" 開頭，並且附上購物內容資訊。沒問題就回覆 OK, 有注意事項就回覆 HINT
```

FAQ 清單，按照 GPTs 的作法，應該用 knowledge 的方式另外上傳，或是我應該靠文件 + 向量資料庫，在處理過程中靠 RAG 檢索。不過資料量不大，加上 POC 我不想引入過多工程細節，這 POC 我就直接附加在 prompt 後面了。

FAQ 清單如下:

```

以下是 FAQ 清單:
1. 若購物車已經是空的，客人又嘗試清除購物車，可能碰到操作異常。請直接詢問是否需要幫助。
2. 若購物車是空的，客人嘗試結帳，可能漏掉部分操作。請直接提醒客人留意，並在結帳前主動列出購物車內容再次確認。
3. 購買含酒精飲料請提醒客人年齡限制，法律限制，避免酒駕。
4. 購買含糖飲料請提醒客人注意醣類攝取。
5. 購買含咖啡因飲料請提醒客人注意咖啡因攝取。
6. 有預算要求，請留意折扣規則。部分優惠折扣可能導致買越多越便宜，請代替客人確認是否多買一件真的會超過預算。

```

2. 結帳時，客人可以輸入一段話，描述任何額外需求


3. 每次交易執行當下，都會組合這段訊息，然後送到 chat completion 取得回應:

```
我要開始結帳，沒問題請回覆 "OK: "，有注意事項請回覆 "HINT: "。其他建議可以在回覆之後接著說明

以下是我購物車內的清單:
{{ 插入購物車的商品內容清單 }}

購買註記:
{{ 插入結帳時客人填寫的註記 }}

```

按照 prompt 的指示，只要 chat completion 回覆 "OK"，UI 就不會有任何異狀，會直接進行結帳。而如果 chat completion 回覆其他訊息，UI 就會用醒目的黃色，提醒客人留意這些訊息。必要時客人可以選擇取消結帳，重新調整後再結帳一次。


直接看結果吧，我列幾個情境，然後讓各位看看 "安德魯小舖" 給客人的結帳提醒。同時各位再試想看看，如果沒有 AI 的輔助，你要花多少功夫才能做到一樣的水準? 


範例 1, 購買清單包含啤酒, 需求間接提到未成年兒童的聚會用途

購買清單:
1.

購買註記:

店長回應:


範例 2, 開車

購買清單:

購買註記:

店長回應:


範例 3, 買可樂, 高熱量

購買清單:

購買註記:

店長回應:

<!-- 
這邊我用了 Azure Open AI 的 API, 搭配 Microsoft Semantic Kernel 1.3.0 來使用。我用的不多，就是使用 ChatHistories, 搭配 ChatCompletionService 而已。程式碼沒有什麼特別的 ( 用過 SK 的大概都看得懂 )。

這案例我沒有另外建立 RAG 索引來源，我是偷懶直接寫在 system prompt, 用一段 FAQ 來替代。當這些資料量大，或是需要從別的系統來，就要動用到 RAG 了，這時可以參考 KernelMemory 的用法。這部分就留給各位自己研究 -->


這邊，開始打開了一條路，要使用 GPT4, 不再是只有 Chat GPT 一個管道而已。就算你寫成 code, 也不需要像市面上大部分的範例，都在教你復刻一個 chat application ... 真正有威力的是把 LLM 的邏輯判斷能力加到你的產品中，讓你的產品開始有 "智慧" 的判斷能力，才是他的發揮場景。


// 關鍵: system prompt


## 1-3, with Shop Copilot

接下來，這段就是我為何要在 2024 年這時代，還搞一個 30 年前的操作介面的原因了 XDD

GitHub Copilot, 相信大家都用過了吧? 我才打完一行 code, 他就猜出我想幹嘛, 然後提示一串 code, 而且命中率高的可怕, 不只語法正確, 連我的意圖都很準 (對我而言，大概有八成都被猜中了吧)。

除了建議很有用之外，另一個是他幾乎不需要學習 (我只有怎麼安裝跟啟用有看一下文件)，因為它完全沒有改變你的操作方式，你只要如往常的寫 code, 他會躲在 IDE 背後默默觀察, 等你有需要時他自己會跳出來給你提示，你只要看到提示時決定要不要接受就好 (就按下 tab)

中了 GitHub Copilot 的毒之後, 做完 "安德魯小舖" 的 POC，我也在想，如果我要做個 安德魯小舖 Shop Copilot, 程式的結構該怎麼調整? 其實這是我上一篇文章寫完後，第一個念頭。我也找了很多文章，想參考看看別人的 Copilot 怎麼寫的，程式碼架構怎麼規劃的，不過這方面的資訊少的可憐啊... 

於是我就自己腦補了，有點雛型出來，我也不知道是否有更好的做法。不過至少達成我的目的了，我的 "安德魯小舖" console-ui 也開始有基本的 copilot 功能..

先來看一下畫面。基本上 DarkGray 幾乎看不到的灰色可以不要理他，只看顯眼的顏色就好。正常操作的回應，都是綠色的，訊息都是白色的，提醒是黃色的。我的設計是例行操作，當 shop copilot 發現有異狀的時候，就會插入提示訊息。

我用很糟糕的 UI, 就是想凸顯這問題。當使用者的操作包含太多無效的指令，背後的原因可能是客人真的不會用，而不是他故意一直下這種指令。這時不是顯示錯誤訊息，而是引導才對。我試了這幾種狀況:

案例: 一直詢問指令表

案例: 不斷的加入  & 移除商品

案例: 空的購物車就結帳

案例: 一次加入太多商品進購物車



要達成這功能，背後的關鍵還是在 prompt . 我該在 system prompt 讓 AI 了解他的職責該 "留意" 什麼? 而我該在 FAQ / SOP 讓 AI 知道有哪些常犯的不良操作示範? 而操作過程中 UI 該如何讓 AI 知道客人做了什麼..

於是，我擴充了 system prompt (我把 FAQ 一起放進來了，這邊我還不打算搬出去改用 RAG):

```
你是 "安德魯小舖" 的助理店長, 負責協助引導每個來商店購買的客人順利結帳。
主要任務有三類:
1. 結帳前的確認
2. 選購過程的操作過程關注
3. 回應客人的問題或是操作要求 (可呼叫 function call)

以下是這三類任務的流程說明:                

結帳前請檢查下列項目:
1. 客人購買的東西是否適合他的期待? 請協助客人確認購買清單。
2. 客人的購買行為是否安全? 請協助客人確認購買行為。有些商品有法律限制，或是有可能對客人造成危險。
3. 客人的購買行為是否合理? 請協助客人確認購買行為。有些商品可能有更好的選擇，或是有更好的折扣。
4. 檢查 FAQ 清單
5. 確認方式: 客人提示訊息會用 "我要進行結帳確認: XXX" 開頭，並且附上購物內容資訊。沒問題就回覆 OK, 有注意事項就回覆 HINT

選購過程的操作過程關注:
1. 如果購物車是空的，就進行結帳，代表客人可能遺漏操作步驟。請提醒客人留意，並在結帳前主動列出購物車內容再次確認。
2. 如果客人連續加入/移除商品超過 5 次，可能是系統異常，或是需要諮詢才能決定。請直接詢問是否需要幫助。
3. 如果客人加入購物車的商品數量超過 10 件，可能是操作異常，或是需要諮詢。請直接詢問是否需要幫助。
4. 如果客人連續顯示操作指令清單 3 次，可能是不熟悉操作，或是找不到他要的功能。請直接詢問是否需要幫助。
4. 確認方式: 客人提示訊息會用 "我已進行操作: XXX" 開頭，並附上操作內容。沒問題就回覆 OK, 有注意事項就回覆 HINT

客人開放性問題詢問或要求協助:
1. 如果客人詢問的問題需要呼叫查詢的動作，你可以直接執行不必詢問
2. 如果客人要求變更購物車內容，或是要你替他結帳，請再次確認，客人同意後才可執行
3. 任何 function 呼叫，完成後都需要明確讓客人知道你呼叫了甚麼 function，並且告知執行結果
4. 確認方式: 客人提示訊息會用 "店長請問: XXX" 開頭，，就歸類在開放性問題或是要求協助。


以下是 FAQ 清單:
1. 若購物車已經是空的，客人又嘗試清除購物車，可能碰到操作異常。請直接詢問是否需要幫助。
2. 若購物車是空的，客人嘗試結帳，可能漏掉部分操作。請直接提醒客人留意，並在結帳前主動列出購物車內容再次確認。
3. 購買含酒精飲料請提醒客人年齡限制，法律限制，避免酒駕。
4. 購買含糖飲料請提醒客人注意醣類攝取。
5. 購買含咖啡因飲料請提醒客人注意咖啡因攝取。
6. 有預算要求，請留意折扣規則。部分優惠折扣可能導致買越多越便宜，請代替客人確認是否多買一件真的會超過預算。

```

而我在每個指令的 CommandProcessor, 都會送出一行 "我已進行操作: " 開頭的提示訊息:

(列出 command processor 與 notify prompt 的對照表)

處理的規則跟前面差不多, 我就簡單的處理而已: 傳回的訊息如果是 "OK" 開頭就不反應，代表沒有需要留意的狀況；如果不是，則用黃字提示。客人看到提示之後，自己決定如何操作即可 (這邊我還沒有實做像 GitHub Copilot 那樣幫你完成的功能，不過看到下一段你就知道這已經可行了，只是我礙於 console-ui 的設計限制沒有做到這裡)

想到這邊，我不禁開始佩服 GitHub 了。做過才知道，GitHub Copilot 不知道在背後送了什麼訊息，才能做到速度那麼快，同時又能精準地提示的結果。我背後用 Azure Open AI 的 service, 都要等幾秒才有回應，到底要倒多少資訊出去，也是個學問。除了效率問題之外，成本也是個問題。如果照我這樣的做法來開發 GitHub Copilot, 一個月只收 $10 USD 應該會賠錢賠到脫褲吧 XDDD

還有非常多優化的空間，不過，至少我自己把雛型做出來了，未來真的碰到類似的需求需要設計架構的時候，我就知道有那些瓶頸需要克服了...

// 關鍵: notify


## 1-4, with Shop Assistant




// 關鍵: function calling








我想像中，安德魯小舖的進化過程，可能有這幾個階段:

1. 典型的 Web / Mobile 應用程式 (現況)
1. API 化，透過 Chat Bot, 在各大平台上 ( ex: LINE, facebook messenger ... etc ) 提供服務 (現況, 但是只有機械式的選單操作。缺乏自然語言的處理能力，要說是智慧，能靠對話完全取代現有操作方式還太早)
3. Copilot 化, 以現有的操作方式 (1) 為基礎, 但是開始在關鍵行為 (例如: 結帳) 能夠靠 AI 給出適當的建議與提示。靠 AI 的資訊彙整能力，APP 開始能貼近使用者意圖而給出正確的建議資訊。( 風險管控角度，數據統計推測角度，在關鍵操作時給適當的提示，例如 “買這個的人都會加購 XXX，這些組合你是不是打算要去 OOO? 要不要加購 YYY ?” )
4. Copilot 化, 在操作過程中全程引導。AI 開始能夠感知你的操作過程，能夠在過程中 (你還沒到結帳那個步驟) 就能猜測到你的狀況，而適時給你建議與引導。( 觀察完整操作過程，助理的介面從旁提供協助或是提示。過去都是由 UX 設計來 "猜" 使用者的下一步，作法對了，但是 "猜" 的範圍很有限 )
5. Agent, Jarvis 化, 操作介面開始取代現有的操作方式，以完成體的助理樣貌出現。只要你願意，Agent 可以完全替你執行操作，就像鋼鐵人的 Jarvis 那樣，使用者不需要直接接觸到操作 UI。使用者不需要學習，就是對 AI 講話就完成操作

這整個過程，需要發展多久? 我覺得如果在特定平台或範圍內，要做到 (5) 應該不需要太久，可能會更快，但是在 3 ~ 5 年內應該一定會看的到。看看現在 Micosoft Copilot 跟 Open AI 的發展，我覺得技術發展應該都快要到位了，在等待的是廣大的軟體開發人員跟上而已。我覺得改革已經發生，方向與局勢已經底定，科學理論的問題已經被證實了，剩下的都是工程角度的改善 & 優化。

什麼是我指的工程角度? 舉例來說，你可以說現在的 LLM 還不夠 "聰明"，成本還太高，但是現在的 GPT4 已經有不錯的表現了，即使還不如你期待的 "聰明"，但是他至少有足夠的對話能力，而不是幾年前的語言白癡。而成本與運算能力，就相信模型能夠不斷地縮小，而半導體摩爾定律也能不斷的前進，AI 運算能力每 18 個月都能改善十倍..
<!-- 
上一篇文章，我實做了 Chat GPT 版本的 “安德魯小舖” GPTs, 嘗試一次到位，試試看 (5) 是否能夠實現。結果證明，在有夠好的語言模型 (LLM) 加持下，最困難的門檻已經跨過去一步了，剩下的都是工程問題 (改善 & 優化)

不過我心裡很清楚，現實上這樣的應用程式應該賺不到錢吧? 門檻太高 ( 使用的人都需要有 Chat GPT plus 訂閱 ), 成本也太高 ( AI 運算很貴，GPT4 token ( $0.03 / 1K tokens, $0.06 / 1K tokens )，或是每人每月 $20 訂閱費用，相較單純 VM 運算成本 根本差上萬倍了吧 )，可靠度也完全不夠 ( Chat GPT 我一個月會碰到一兩次太慢或是無法使用的狀況，也常常碰到額度超過的狀況 )，相較於傳統的操作，效率也太慢 ( 你熟悉的話，瀏覽 + 點擊 + 確認 速度快的多 )，AI 回答的不確定性 ( 幻覺，偷懶，… etc )

也許 10 年後真的就普及了吧 (可能更快)，產業的進步，這些問題一定會一一的被解決掉，只是時間問題。不過我在想的是，中間演進的過程會是什麼? 這才是我關心的事啊，因為在未來 10 年的職涯內，我一定會碰到這些問題。在完成 "安德魯小舖" GPTs 後，我放心了，因為我清楚知道這條路是可行的，剩下的應該是回頭把過程中幾個必經的轉變找出來，這就是我未來要陸續面對的課題。

因此，就有了上面的進化順序了。若把未來定位在 Jarvis 那樣的情境 (所有事情都只要出一張嘴)，那現在還遠的很。還有太多工程問題待解決的話，我 ( 架構師, 開發人員 ) 應該先把 AI 用在刀口上。

我不是 AI 的專家，也不是資料處理的專家，擅長的領域只有軟體開發而已。 -->

所以，上述這些想像，換成具體的規格 (我有對應的 demo)，我就用這幾個 demo 來說明了:

1. 無智慧的對談介面 ( 安德魯小舖 - console ui )
1. 結帳時能由 AI 給回饋與建議 ( 安德魯小舖 - copilot-confirm )
1. 操作全程能由 AI 給引導與建議 ( 安德魯小舖 - copilot-notify )
1. 操作過程能完全由 AI 主控 ( 安德魯小舖 GPTs, -copilot-ask + function call )