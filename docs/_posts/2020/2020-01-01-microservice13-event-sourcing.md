---
layout: post
title: "微服務架構設計 - Event Sourcing"
categories:
- "系列文章: .NET + Windows Container, 微服務架構設計"
- "系列文章: 架構師觀點"
tags: ["microservice", "系列文章", "架構師", ]
published: false
comments: true
redirect_from:
logo: 
---


// TODO: Command Pattern

// DEMO: CQRS + Event Sourcing, Implement Distributed Transaction (not 2PC, using SAGA patterns)

// 優化 - 局部 code 改寫, 改用更好的元件，框架，服務；
// 架構 - 用不同的手段解決問題，演算法，處理流程


好久沒寫微服務系列的文章了，前陣子有個專案的關係，開始認真的評估 "Event Sourcing" 的設計方式，就順手寫篇心得來記錄一下。這次不寫那麼長了 (希望啦)，我想記錄一下到底甚麼場景下，你才真的需要使用到 Event Sourcing 的設計架構...。




# 簡介: 什麼是 Event Sourcing ?

其實 Event Sourcing 不算是新架構或是新觀念，早在 2000+ 的時候就很多人在討論了；我找了篇大神寫的文章: Martin Fowler - pEvent Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html) 來當作代表就好了。所謂的 Event Sourcing, 其實背後的理念就是:

> 要儲存的，不是最後的資料，而是記錄讓資料改變的資訊歷程；如果你能完整記錄這些歷程，你就有能力還原任何時間點的資料狀態。

從定義上來說，如果你的 input 是以 "異動" 的過程為主，那麼你的紀錄就變成 log 型態的流水帳了。先不講優缺點，這樣做有幾個系統層面的特性:

1. 紀錄只會增加，你不能也不應該異動這些歷史資料。因此資料處理的模式從一般的 CRUD，簡化為 CR 而已。D 變成有限度的操作 (例如 archive) 而已。
1. 配合記錄流水帳的需要，前端處理通常會搭配 CQRS，強迫資料的異動進入資料庫前就被序列化
1. Event Sourcing 會帶來一些好處，但是不利於頻繁的計算最終結果的操作。通常架構上需要搭配 CQRS 同步更新 aggration view






講的白話一點，你拿出你的存摺出來看看就知道了。存摺清楚的按照時間序，把你每一筆款項的進出都記錄下來，何時存款，何時提款等等；每一筆異動紀錄，最後面才會附上當下結算的帳戶餘額。

然而，存摺是一筆一筆的印在本子上的啊，印出來的紀錄就不會被消掉了，紀錄只會不斷的往後面附加上去。想像一下，銀行能在本子上打出這些資料，他背後一定是這樣紀錄資料的。這樣的好處顯而易見:

1. 紀錄資料異動的順序，可以完整保存異動的過程 (而非只是記錄結果)
1. 有需要時你能有足夠的資訊重新還原過程
1. 來源資料只會 "新增"，不會更新也不會刪除。適合交易相關的資料處理 (要保留流水帳)

...

這樣做有什麼好處? 如果你在設計銀行的系統，試著想像一下下列情境:

> 如果交易過程中，有帳務弄錯了 (例如算錯利息)，我有能力修正後重新計算最終的結果, 然後追加一筆補差額的紀錄嗎? 

這邊的對照組是: 我只替每個帳戶紀錄最後的餘額，每次有資金異動，我就會用 update 的方式更新餘額 (當然我為了保險起見也會寫下 log)。但是，log 跟 event sourcing 的 event 紀錄最大的不同是, event 本來就是來源資料, 我可以拿來重新計算；log 則只能拿來查閱, 我很難再匯回系統按照 log 重新計算一次啊...

很顯然的，這些好處，都建立在完整的 event 紀錄上，缺點也是顯而易見的，我必須耗費大量的 storage 跟運算能力才能支撐這樣的設計... (至於 developer 的技能要求門檻就更高了，這部分我就不討論)，沒有必要的話這也不見得是個好設計。


好，先做點功課，先了解 "event sourcing" 到底是指啥, 入門介紹先到此為止，其他觀念後面再探討。


# 雲端時代的架構設計觀念 - cloud native

"Cloud" 這名詞，喊了十幾年了，到現在已經不算是啥新技術了，而是到處都看的到的應用了。不過很多開發人員，開發跟架構的思維還是沒有轉移到 "cloud" 啊! 我在繼續這主題前，我先亂入這段...

引用我半年前在 facebook 貼的一段[評論](https://www.facebook.com/andrew.blog.0928/posts/848315655543714):


```

這篇文章還不錯，介紹了 google 技術發展的過程。這勾起了我當年 (2008 剛開始在談雲端的時候) 看到 google 如何走出不一樣的路時的震撼...

更早 2000 年的時候，企業的 IT 當道，主流都還是 windows server 的年代。當時 server 都是靠更高級的設備堆出可靠度的, 舉例來說: 如果一顆硬碟的故障率是 1% 的話，用 RAID1 就可以把故障率降低到 0.01% ..., 這已經是 99.99% 的 SLA 了，而且你有機會在服務掛掉前替換故障的硬體... 所以程式開發人員就可以有個可靠的平台，不需要傷腦筋可靠度這件事，只要有可靠的 IT 幫你照顧好 server ...

但是這個前提在雲端 (planet scale) 的年代就被打破了。再高級的硬體, 如果乘上極大的數量 (例如: 10000 台 server)，那麼這個故障率就又被放大到不可忽視了。

Google 當年其中一個核心觀念就是: 在某個規模之上，硬體的故障就是不可避免的。與其在硬體上不斷靠備援來拉高可靠度，不如在軟體服務的設計上，本身就允許設備的故障...

因為這個觀念，才發展出 BigTable 這類儲存方式，一份資料存放三份，故障了就整個節點直接離線，重新建立損失的那一份資料。整個 cluster 就像有機體一樣可以自行適應不完美的環境...

另一個重要的變革就是 MapReduce (我是看不懂複雜的論文跟演算法啦)，同樣背後有很基本的觀念改變: 資料量大到某個規模以上的時候 (例如: PB 級以上)，傳統資料庫的架構就不適用了。資料庫都是以 "運算" 為中心的，強大的 server 有足夠的 CPU / RAM 等運算資源，搭配有高可用性的 storage, 組成效能強大的資料庫。不過先天的限制是，這架構都是把 "資料" 送到 "運算資源" 端才進行運算的... 效能瓶頸都卡在 I/O, 試想你要查詢的資料遍及 1PB (散在 1000 顆 1TB HDD), 你要多久才能夠掃完所有的資料?

與其把 Query 交給少數幾台 Server, 然後負責查詢的 Server 才想辦法把資料從 1000 HDD 拉回來查詢，MapReduce 則是完全反轉這個觀念，反過來以 "資料" 為中心，將 "運算(Query, 大概就是一小段 code)" 送到資料端就地的 Server (每台 server 可能只掛幾顆硬碟) 進行運算，然後再把運算結果集中起來。就地的運算就能避開跨網路大量的傳遞資料，反過來是本機查完資料後再透過網路收集結果。MapReduce 不但有效避開大量的 I/O 瓶頸，同時也大幅提高了 scalability, 能用極大的規模處理平行運算。

要支撐這樣動態且快速變化的系統, deployment, containerize, immultable server, health check, service discovery, service registry 等等機制都變成是必要的, 這些一路演變至今, 成就了目前 cloud native 的重要基礎。也難怪 Google 早期就有這樣的發展經驗, 融合這些開發與管理經驗的 K8S 才會那麼快的席捲整個 container orchestration 的市場..

蠻有意思的改變，當年搞懂了 Google 這些改變，加上念書時分散式系統有打好基礎，進入雲端服務的時代後，有這些基礎都能很快的就理解許多新架構葫蘆裡是在賣甚麼藥.. 觀念搞懂後剩下的實作就容易了。熟悉仍然要花不少功夫，但是觀念通了之後，熟悉工具花費的時間是線性的，搞懂觀念要花費的時間則很難預料..

講了一大堆，難得看到文章會講這種發展故事的，有興趣的話可以花點時間看一看 

```

[谷歌在微服务上的坑和教训](https://www.infoq.cn/article/L*bT1UfuVoj1I6NRNM3U)

我在這邊，特地提到 "cloud native" 的原因，主要就是我上面評論講的，很多時候，我們講的 cloud, microservices, big data... 等等, 不單純只是指 "流量很大"，或是 "交易量很大" 這類指標的差異而已；更大的差異是，本質上計算的架構已經完全不同了，所以你會需要有完全不同的架構設計方式。然而微服務背後的設計理念, 完全就是 cloud native 那一套, 只不過 microservices 更強調的是服務的切割方式與切割的邊界。在我看來是同一件事的一體兩面，後面我就都用 cloud native 當作代表了。

舉例來說，我在 2000 年那個年代，工作上大都是三層式架構 (有的還只有兩層)，一組 WEB，一組 AP，一組 DB 就搞定了，哪有甚麼分散式的觀念? 不過到了 Google 的規模，數量及改變了，很多觀念不再適用，才開始有了 "cloud native" 的轉變啊! 上面提到的都是各種例子，我認為這篇講到的 event sourcing 也是其中一例。

與其說 "event sourcing" 是要解決瞬間巨量，處理巨量資料，提高可靠度.. blah blah 等等，我都覺得那些只是最終的結果，你如果有這些目的，其實你會有更多直接有效的技巧，同樣能滿足目的。真正需要認真思考 event sourcing 這技術，我認為這本質上是純架構的選擇, 為了同時保存原始 event 的紀錄，同時用 streaming processing 的方式, 在收到資料的當下就處理好資料, 直接用你將來想查詢的方式預先處理好後存下來的作法, 歸納出來的架構模式, 就是 event sourcing。

真的要看細節，這篇說的很到位:

[深入浅出Event Sourcing和CQRS](https://zhuanlan.zhihu.com/p/38968012)


我再把話題拉回 cloud native 這件事身上。當你運算規模大到某個程度, 你就應該採取不同的處理策略了。跨過那個數量及, 你所要採用的整套架構, 就應該改以 cloud native 為主了。我不直接談論 event sourcing, 我談他被後的處理方式。關連式資料庫，強調正規化，同樣的資料盡可能的正規化，不要放兩分，需要在靠關聯重新 join 回來，你就可以做到一致性。然而 cloud native 的處理策略則反過來, 收到資料當下, 就做好必要的處理，包括複寫到所有你要擺的地方，預先做好你要的處理；資料的正確性不靠交易與鎖定，而是靠可靠的通訊 (例如 message queue) 來將資料序列化與確保會被執行, 犧牲強一致性，換取最終一致性。

最大的差別，就是你能乘載的規模。這邊指的規模，不一定都是指淘寶雙十一那種瞬間巨量, 而是指你的架構能限性擴充的上限。指的不一定式線上的交易量，也可能是指你能夠處理的資料上限。舉例來說，採舉 join 的方式，在需要時才還原成你要的樣子，某種程度都會受資料總筆數的影響。相關的時間複雜度，取決於你的索引與你的查詢下的好壞。我就拿 O(log n) 當範例好了。但是如果用 cloud native 的思維去設計, 收到一筆資料就處理, 對於 DB 的操作都是用 key 去取得對應的 value, 時間複雜度通常會是 O(1), 而你要取得處理後的資料通常也是 O(1)... 很明顯的, 單筆資料不見得快, 也不見得能真的做到強一致性, 但是對於你能處理的規模上限, 或是線性擴充的能力, 則 cloud native 這派的哲學則是遠遠領先。

所以回到 event sourcing, 我會認為這只是 cloud native 整體思維下的一個常用的 pattern 而以；你通常不會 "單獨" 的使用 event sourcing 來解決問題。後面我就舉個我前陣子專案上碰到的例子，來說明一下我的想法。


# Event Sourcing 應用案例

我先把幾個名詞列一下，如果有你不懂的可以先預習一下。看懂後再往下看才不會一頭霧水。幾個必要的知識:

1. Message Queue
1. Streaming Data Processing
1. CQRS (Command / Query Responsibility Segregation)
1. DDD (Domain Driven Development)
1. No SQL (key value store)

原諒我工作上的案例，不能描述的太精確，我就舉一個典型的應用，套上我專案處理的架構來說明吧! 這樣大家可以同時了解概念，我也不需要過度暴露專案的細節。我就繼續沿用上述銀行存摺的例子好了。首先，核心業務一定是你的帳戶管理。來看看這段的設計:













// 2021-05-25 notes
https://www.facebook.com/andrew.blog.0928/posts/1400700806971860



#校正回歸 - 談 資料處理的時效性

篇幅有限，我就講重點就好。長篇大論留在 blog 慢慢探討..

今天下午記者會之後，大概全 FB 都被 #校正回歸 這四個字洗版了，我覺得這是很正常的事，必然會發生的啊... 今天不談疫情也不談政治，單純談系統架構就好 :D


認識我的人大概都知道，我公司開發的是跟交易相關的系統，包含線上跟實體門市的交易。如果兩者的資料有時間差，今天的業績線上交易過了 12:00 馬上就能統計出來，而實體門市交易要隔 1 ~ 3 天才能結算完成，我在周一開張一家新的店面，那麼..

星期二: 我們昨天(一)的營業額是 100 萬
星期三: 我們昨天(二)的營業額是 120 萬
星期四: 我們昨天(三)的營業額是 110 萬
	另外，門市結算出來了，週一的營業額是 350 萬..
星期五: ... (以下省略)

問大家一個問題，我該把週四收到的 350 萬營業額，歸在拜一? 還是拜三?

別急著說答案啊 XDD, 要看這些數字之後要拿來做什麼用途... 這背後帶出來的就是兩件事的衝突: (A)系統期待的資訊回應速度 vs (B)資料收集與處理的延遲 兩者之間的差異。

我在資訊業待了 20 年了，從當年都是批次處理，到現在雲端網路那麼發達，什麼資訊都可以即時傳遞的年代，加上系統要處理的資料規模越來越大，(A) 跟 (B) 的落差也越來越大了。

當 (A) 越來越要求即時 (以台灣疫情記者會 每天 14:00 舉辦為例，前一天的疫情統計大約只有 4hr 的處理時間)，而 (B) 的處理速度 (前一天採檢，到能知道結果是否確診) 難以大幅加速跟上的前提下 (包含檢驗速度，跟檢驗的處理量)，當 (B) 跟不上的時候，(A) 就一定會發生需要 #校正回歸 的狀況。因為我的 (B) 還沒處理完，但是數據報表 (A) 已經出去了...

所以回到前面的問題，星期三收到的門市業績 350 萬，到底要算周三的業績? 還是周一的業績?

我的答案是: 如果老闆想看看週二下了廣告到底有沒有效果，那 350 萬當然要歸類在交易發生的當下時間 (周一) 啊! 不然我怎麼知道我的廣告有沒有效? 處理需要時間，在我能改善之前我只能等。線上的業績能提早看到，你要不要看? 當然要啊! 多個參考資訊總是好的。重點在於老闆心裡要先知道，還有一部分資料沒到齊就好...

如果這些資訊是我要考慮現金流，或其他用途，我必須先確定我有多少營業額才能做決定的 (抱歉這邊我例子沒辦法舉的很精準)，實際交易發生的時間對我不重要，而到目前確實發生過的交易金額對我更重要的話，那我就會希望在週四一起看到這些數字。他不需要硬被歸在拜三的業績，但是我希望拜四的報表要看到這數字，否則我無法做決策..

所以回來看看，這次中央疫情指揮中心的做法其實很合理啊，這數字的目的，是讓社會大眾能知道疫情的溫度是上升還是下降，要判斷疫情的嚴重性才是主要目的，當然是要回頭修正過去的資料。我覺得資訊能夠透明，並且據實以告，比什麼都重要。真的要挑毛病，我認為可以做更好的是: 應該在前幾天宣布數字時，就該說明檢體並沒有完全處理完畢，日後這些數字還會修正，而不是今天才給大家一個驚喜，並引起一些不必要的混淆跟攻擊。

回到系統的架構來看，那這類問題該怎麼處理才洽當? 資料量越來越大，系統要求回應的速度越來越即時，各領域的系統都會很容易的碰到這種狀況。簡單的說我會這樣處理:

1. 定義資料發生的時間與收到的時間，兩者是不同的
2. 資料的處理善用 Event Sourcing 的機制處理，按照時間序進行，資料來源要能完全反映資料取得的狀況 (包含修改)
3. 要呈現統計，或是處理過的結果，請善用 CQRS 的模式。將資料修正成你要的樣子。你有兩種以上的呈現需求，就應該用兩組 view 來處理
4. 就算架構面你有做好，也不代表資料處理的延遲能無限制的放大。需要定義系統能忍受最大延遲時間 (例如 5 days), 超過的一律要走例外處理的流程了。財務算錢都會有個 "關帳" 的時間點，這就是一例，關帳之後不管你有任何理由，這筆帳就算在下個週期..

這個問題，其實我想了很久了，用了很多案例，我才終於想通怎麼兼顧系統的回應時間 (能不能看到即時業績報表?)、資料的正確性 (延遲的資料怎麼正確的呈現)、還有資料處理的架構怎樣用一個既簡單又優雅的模型來說明?

這就是架構師的任務啊，也是個很傷腦筋的題目。我有一篇要探討 Event Sourcing / CQRS (Command Query Responsibility Segregation, 命令與查詢責任分離) 的文章，寫到一半而已 XDD, 內容就是在講上面那堆問題背後的細節。趁著時事，先丟我的想法，想看文章的記得關注我的粉絲團 :D










--

#校正回歸 背後的現象...

突然整個下午，不管在甚麼地方 (我指線上，我都乖乖宅在家)，不論是 FB, Line, Twitter, PTT 等等，各式各樣的話題都會被 #校正回歸 這名詞置入... 其實這狀況很普遍啊，只是過去你沒留意到而已。有多普遍? 我舉個例子來說明..

這問題我想了兩年了，差別在於兩年前我覺得是個難題，一年前我想通了不過還在思考系統層面怎麼處理才漂亮，現在則是連系統層面也想通了。舉個實際的例子好了，我們公司的系統都在處理交易資訊，包含線上的交易，也包含實體門市的交易。我舉個簡單的例子:

"如果我有一套系統能 24hr 即時顯示交易狀況，但是門市的系統跟不上，必須延遲一段時間才能上傳交易資訊，那我到底該如何 [定義] 即時資訊?"

拿案例來說，如果我用以下的時間序來說明真實世界發生的狀況:


09:00	C 在門市買了 2000 元的東西
10:00	A 在線上下單，買了 1000 元的東西
12:00	B 在線上下單，買了 1200 元的東西

21:00	門市盤點

(隔日)
02:00	門市的系統把昨日的交易資訊上傳 ( 09:00, C, 2000 )

這時，你身為 user (通常是老闆)，你想要在這套 "即時" 的系統看到什麼? 按照標準的工程思維，應該是這樣:

[即時交易資訊]

09:00	+0	0
10:00	+1000	1000
12:00	+1200	2200
21:00	+0	2200

(隔日, 歸零)

02:00	+2000	2000

這很符合工程的想法啊... 不過這擺明不是老闆想看到的。老闆想看的應該是更貼近事實的資訊，應該是這樣:

[即時交易資訊]

09:00	+2000	2000
10:00	+1000	3000
12:00	+1200	5200
21:00	+0	5200


不過問題來了。門市的資訊就是隔天才會進到系統，在那之前系統不論做任何努力，都不可能挖出這筆資料的，除非資訊已經數位化，並且存在於某個能被 access 的地方才行。

這時，你怪罪 RD 是沒有用的，應該先來思考一下這之間的矛盾:

1. 即時的需求 (指標: 延遲 1 min 內) 越來越高
2. 資訊的延遲 (指標: 發生 ~ 收到資訊 24hr 內) 跟不上

當兩者的落差越來越大，這幾年 (1) 不斷地縮短，(2) 沒有跟上來的話，資料的 "時間差" 問題就越來越難處理。今天記者會陳時中部長講的 #校正回歸 不就是這回事嗎? 疫情大家越來越關注，因此每日回報的資訊，大約只有 14 小時的處理時間 (前一天過完 00:00 ~ 隔天記者會 14:00), 這還包括晚上是大家的休息時間。

然而採檢確認結果是需要時間的，有處理能量的問題。資訊上報也是需要時間，跑公文或是審核等等也需要時間，彙整統計驗證資料也是，這些過程只要跟不上，這個現象就發生了。過去一年多，台灣防疫成績都維持在個位數，這陣子急速飆升到 300 上下，臨時的流量導致延遲，從系統層面上來看是必然發生的，延遲到超過 (1) 即時的需求，就造成今天的現象了。

畢竟我要討論的是架構問題 XDD，所以回到上面的案例，那這套系統該怎麼修正才合理?

我先假設收集資訊就是需要時間處理，這部分無法改變。這樣的話，這套系統光是需求就有矛盾了 (這是個注定辦不到的需求)。在合理的範圍內，我們也許可以拆開來看:


[即時交易資訊: 線上]

09:00	+0	0
10:00	+1000	1000
12:00	+1200	2200
21:00	+0	2200

實體的資訊當然也可以用同樣的方式處理，只是你註定無法即時看到。因此那兩個字應該要拿掉才對 XDD

[____交易資訊: 門市]
02:00	+2000	2000


我繼續把問題往後推，如果這些資訊的下一步，是產生每日報表，這些報表算出來的數據是要做後續的財務處理用的 (例如: 計算收入，計算拆帳資訊等等)，然後這問題又剛好碰到跨越週期，那該怎麼辦?

合理的做法是定義容許資料延遲的最大時間 (例如: 72hr), 出這些重要的報表時，必須等這段時間過了之後才能進行。所以常見的公司財務流程，都有所謂的關帳時間，發薪水也不是每月 1 日發放，而是每月 5 日或是其他不等的作業時間。

回過頭來，所以，奢求即時統計的資訊系統是不切實際的夢想嗎? 系統應該修正一下，將功能區分幾個部分:

1. 即時資訊

2. 歷史資訊 (daily, 隔日)

3. 歷史資訊修正通知 (alert)


這麼一來，就能兼顧系統可行性，需求的合理性了。拿這個案例來看今天的記者會，結果就很清楚了。每天記者會回報的數字，其實就是 (2) 的前一天統計啊。當資訊收集處理過程延誤了，就用 (3) 來追加修正。只是這次部長給了 (3) 一個專有名詞 "校正回歸" .. 如此而已。



那麼，又開始有兩派的人在爭論了，這修正的數字，到底要歸在今天還是實際發生的時間?

我的看法是: 看資料的用途。

如果這資料有後續任務要接手處理，是要派工的 (例如確診者須要進一步追蹤醫護) ，應該加到今天的範圍啊，不然他就被漏掉了。

如果這資料是事後要用來分析實際狀況或是趨勢的，那應該要回填到當日的資訊內。這樣資訊才能真正反映現實狀況，只是收集過程中不同步，需要修正而已。


如圖:

187367547_10161327933016030_7427186505657924933_n.jpg


如果你是工程師，看到這裡可能會抓狂了，啊一份資料這麼多種規則，我是要怎麼開發...

這就開始考驗你的架構思考跟抽象化能力了。越來越即時的系統，資料的時間維度問題就會被放大，到 2021 年全球化，雲端化，什麼都即時化，架構的設計已經沒有過去那麼容易，把 ER model 定義出來就搞定的年代了。時間維度變成另一個必定要面對的難題。

Cloud Native 的設計思維裡面，其實早就有包含很多成熟可靠的 pattern 了啊! 以我來看，你只要能熟悉掌握 Event Sourcing + CQRS 這兩個處理機制，你就能漂亮的解決這個難題。





























